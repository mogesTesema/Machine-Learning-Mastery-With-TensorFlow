{"cells":[{"cell_type":"markdown","metadata":{"id":"h7RYo_wAauKy"},"source":["# Transfer Learning with Tensorflow Part 1: Feature Extraction\n","Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n","There are two main benefites\n","* 1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n","\n","\n","* 2. Can leverage a working neural network architecture which has already learned patterns on similar data to  our own, then we can adapt those patterns to our own data."]},{"cell_type":"markdown","source":[],"metadata":{"id":"K3zxjitXLxhl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4b5Q4_bJ-Gw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1760420164000,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"pyEHqeWAcTpr","outputId":"92a44e8f-d91d-4a1c-f72a-23d8959d4d00"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1f9ecf33-0b3f-4583-be4b-171747214f30\", \"04-transfer-learning-in-tensorflow-part-1-feature-extraction.ipynb\", 38488)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!pip install tensorflow\n","import tensorflow as tf\n","# from google.colab import files\n","# files.download('/content/drive/MyDrive/Colab Notebooks/04-transfer-learning-in-tensorflow-part-1-feature-extraction.ipynb')\n","\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"5MKv8CmgdO_a"},"source":["## Download and become one with data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1143,"status":"ok","timestamp":1760347408904,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"LeJJ_16XdZuo","outputId":"0af84988-4349-4349-a8de-604c5eb35f94"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-10-13 09:23:29--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.207, 64.233.181.207, 173.194.193.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M   180MB/s    in 0.9s    \n","\n","2025-10-13 09:23:30 (180 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n","\n"]}],"source":["# Get data (10% of 10 food classes from food101)\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJbi9bRzd3ui"},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile(\"10_food_classes_10_percent.zip\") as ziped_ref:\n","  ziped_ref.extractall()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1760347410790,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"WNr0LtH7eyyA","outputId":"8645d004-48b6-485b-bc86-bb8a3440fdaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["1010140.jpg  1670180.jpg  2256750.jpg  3088660.jpg  3796218.jpg  583603.jpg\n","1036215.jpg  1709710.jpg  2278946.jpg  3101158.jpg  3805565.jpg  604162.jpg\n","1038553.jpg  1761259.jpg  248136.jpg   3125905.jpg  3878886.jpg  607735.jpg\n","1086335.jpg  1802721.jpg  2534877.jpg  3140576.jpg  3912017.jpg  699176.jpg\n","1122669.jpg  1818289.jpg  2565475.jpg  3156598.jpg  396083.jpg\t 73340.jpg\n","1181766.jpg  1821268.jpg  2671820.jpg  3312172.jpg  419342.jpg\t 73783.jpg\n","1228951.jpg  1822493.jpg  2722745.jpg  3346138.jpg  423924.jpg\t 76817.jpg\n","124124.jpg   1828545.jpg  2797268.jpg  3354260.jpg  446192.jpg\t 816775.jpg\n","1301947.jpg  1879189.jpg  29455.jpg    3486079.jpg  460108.jpg\t 91789.jpg\n","1335771.jpg  1903326.jpg  2953924.jpg  3488531.jpg  477600.jpg\t 985020.jpg\n","153931.jpg   2154348.jpg  2988095.jpg  3530013.jpg  509480.jpg\n","1585333.jpg  2207445.jpg  3069250.jpg  3583066.jpg  554810.jpg\n","1635356.jpg  2223416.jpg  3083927.jpg  379510.jpg   577673.jpg\n"]}],"source":["!ls 10_food_classes_10_percent/train/hamburger"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1760347410808,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"JL3nOWQjfze0","outputId":"75e13cfb-0ef8-46f8-f686-15743ee5095b"},"outputs":[{"output_type":"stream","name":"stdout","text":["there are 2 directories and 0 images in 10_food_classes_10_percent\n","there are 10 directories and 0 images in 10_food_classes_10_percent/train\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/sushi\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/hamburger\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/steak\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/ice_cream\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/chicken_wings\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/grilled_salmon\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/chicken_curry\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/fried_rice\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/ramen\n","there are 0 directories and 75 images in 10_food_classes_10_percent/train/pizza\n","there are 10 directories and 0 images in 10_food_classes_10_percent/test\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/sushi\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/hamburger\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/steak\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/ice_cream\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/chicken_wings\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/grilled_salmon\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/chicken_curry\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/fried_rice\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/ramen\n","there are 0 directories and 250 images in 10_food_classes_10_percent/test/pizza\n"]}],"source":["import os\n","import pathlib\n","\n","for dirpath, dirnames,filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f\"there are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"]},{"cell_type":"markdown","metadata":{"id":"AYTxKoXthijN"},"source":["## Create data loaders (preparing the data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1760347410912,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"iJPmKM58jHHt","outputId":"737cd8ed-b3b9-4e8f-8a03-c0cbab3f7f3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training images:\n","Found 750 images belonging to 10 classes.\n","Found 2500 images belonging to 10 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","IMAGE_SHAPE = (224,224)\n","BATCH_SIZE = 32\n","EPOCHS = 5\n","train_dir = \"10_food_classes_10_percent/train\"\n","test_dir = \"10_food_classes_10_percent/test\"\n","train_datagen = ImageDataGenerator(rescale=1/225.)\n","test_datagen = ImageDataGenerator(rescale=1/225.)\n","print(\"Training images:\")\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                                          target_size=IMAGE_SHAPE,\n","                                                          batch_size=BATCH_SIZE,\n","                                                          class_mode=\"categorical\")\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size=IMAGE_SHAPE,\n","                                             batch_size=BATCH_SIZE,\n","                                             class_mode=\"categorical\"\n","                                             )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1760347411484,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"ifPA72SoaVm2","outputId":"18b731c8-a446-4a8c-f45c-d218a13c7b46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 750 files belonging to 10 classes.\n","Found 2500 files belonging to 10 classes.\n","<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))> <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n"]}],"source":["from tensorflow.keras.utils import image_dataset_from_directory\n","train_dir = \"10_food_classes_10_percent/train\"\n","test_dir = \"10_food_classes_10_percent/test\"\n","train_data_10_percent_dataset = image_dataset_from_directory(train_dir,\n","                                                             label_mode=\"categorical\",\n","                                                             batch_size=32,\n","                                                             image_size=(224,224),\n","                                                             shuffle=False\n","\n","                                                             )\n","test_dataset = image_dataset_from_directory(test_dir,\n","                                           label_mode=\"categorical\",\n","                                           batch_size=32,\n","                                           image_size=(224,224),\n","                                           shuffle=False)\n","print(train_data_10_percent_dataset,test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1760347411740,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"9uASVgEofyTm","outputId":"8f4c143a-1111-4017-ecaf-33690d726c5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n"]}],"source":["# normalizing training and validation datasets\n","rescale_layer = tf.keras.layers.Rescaling(1./225)\n","train_dataset_10_percent_rescaled = train_data_10_percent_dataset.map(lambda data,label:(rescale_layer(data),label))\n","test_dataset_rescaled = test_dataset.map(lambda data,label:(rescale_layer(data),label))\n","print(train_dataset_10_percent_rescaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjWT7O5PhgTW"},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_dataset_10_percent_rescaled = train_dataset_10_percent_rescaled.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n","test_dataset_rescaled = test_dataset_rescaled.cache().prefetch(buffer_size=AUTOTUNE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhpAixpRhf6K"},"outputs":[],"source":["data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomFlip(\"vertical\"),\n","    tf.keras.layers.RandomZoom(0.2),\n","    tf.keras.layers.RandomRotation(0.2)\n","])\n","train_dataset_10_percent_rescaled = train_dataset_10_percent_rescaled.map(lambda data,label:(data_augmentation(data,training=True),label))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4eaxCn7HMS0"},"outputs":[],"source":["def create_model(model_url,num_classes):\n","  \"\"\"\n","  Takes a Tensorflow Hub URL and creates a Keras Sequential model with it.\n","\n","  Args:\n","    model_url (str): A TensorFlow Hub feature extraction URL.\n","    num_classes (int): Number of output neurons in the output layer,\n","    should be equeal to number of target classes, default 10.\n","\n","  Returns:\n","    An uncompiled Keras Sequentail model wtih model_url as feature extractor\n","    layer and Dense output layer with num_classes output neurons.\n","\n","  \"\"\"\n","  # Download the pretrained model and save it as keras layer\n","  feature_extractor_layer = hub.KerasLayer(model_url,\n","                                           trainable=False,\n","                                           name=\"feature_extraction_layer\",\n","                                           input_shape=IMAGE_SHAPE +(3,) # 3 for rgb color\n","                                           ) #freeze already learned patterns\n","\n","  # Create our own model\n","  model = tf.keras.Sequential([\n","      feature_extractor_layer,\n","      tf.keras.layers.Dense(10,activation=\"softmax\",name=\"output layer\")\n","      ])\n","\n","  return model\n"]},{"cell_type":"markdown","metadata":{"id":"QJXzzfGymrTK"},"source":["## Setting up callbacks (this to run whilst our model trains)\n","coallbacks are extra functionality you can add to your models to be performed during or after training. Some of the most popular coallbacks:\n","* Tracking experiments with the TensorBoard callbacks\n","* Model checkpoint with the ModelCheckpoint callbacks\n","* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmSGpVlSoOdY"},"outputs":[],"source":["# Create tensorboard callback( functionized because we need to create a new one for each model)\n","import datetime\n","def create_tensorboard_callback(dir_name,experiment_name):\n","  log_dir = os.path.join(dir_name,experiment_name,datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","  print(f\"Saving TensorBoard log files to : {log_dir}\")\n","  return tensorboard_callback\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8TYNcXYCKS0v"},"source":["### Creating and testing ResNet kaggle Hub Feature Extraction model"]},{"cell_type":"markdown","metadata":{"id":"iVN7S92yyBfq"},"source":["\\## Creating a models using Kaggle Hub\n","In the past we've used TensorFlow to create our own models layer by layer from scratch.\n","\n","Now we're going to do a similar process, except the majority of our model's layers are going to come from Kaggle Hub.\n","We can access pretrained models [here](https://www.kaggle.com/models/tensorflow/efficientnet/tensorFlow2/b0-feature-vector/1?tfhub-redirect=true&utm_source=chatgpt.com)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":512568,"status":"error","timestamp":1760347925502,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"},"user_tz":-180},"id":"pKoFcyGpIz0E","outputId":"31fb284c-6395-4a7a-a64b-691e050c6519"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow_hub) (2.0.2)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow_hub) (5.29.5)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow_hub) (2.19.0)\n","Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.12/dist-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (25.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.75.1)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.14.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.9)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n","Saving TensorBoard log files to : TesorFlow_Hub/resNet_model/20251013-092348\n","Epoch 1/5\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0802 - loss: 3.4266"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3807889648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                      \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                      metrics=[\"accuracy\"])\n\u001b[0;32m---> 32\u001b[0;31m history_resNet_model = resNet_model.fit(train_dataset_10_percent_rescaled,\n\u001b[0m\u001b[1;32m     33\u001b[0m                                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_10_percent_rescaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 )\n\u001b[1;32m    411\u001b[0m                 val_logs = {\n\u001b[0;32m--> 412\u001b[0;31m                     \u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 }\n\u001b[1;32m    414\u001b[0m                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["!pip install tensorflow_hub\n","from tensorflow import keras\n","import tensorflow_hub as hub\n","class ResNetLayer(keras.layers.Layer):\n","    def __init__(self, resNet_feature_extractor_url, **kwargs):\n","        super().__init__(**kwargs)\n","        # create the hub layer inside init\n","        self.resNet_feature_extractor_url = resNet_feature_extractor_url\n","        self.resNet_feature_extractor = hub.KerasLayer(resNet_feature_extractor_url)\n","\n","    def call(self, inputs):\n","        return self.resNet_feature_extractor(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"resNet_feature_extractor_url\": self.resNet_feature_extractor_url\n","        })\n","        return config\n","\n","\n","resNet_feature_extractor = ResNetLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\")\n","\n","resNet_model = tf.keras.Sequential([\n","    keras.Input(shape=(224,224,3)),\n","    resNet_feature_extractor,\n","    keras.layers.Dense(10,activation=\"softmax\")\n","])\n","resNet_model.compile(loss=\"categorical_crossentropy\",\n","                     optimizer=\"adam\",\n","                     metrics=[\"accuracy\"])\n","history_resNet_model = resNet_model.fit(train_dataset_10_percent_rescaled,\n","                                        epochs=5,\n","                                        steps_per_epoch=len(train_dataset_10_percent_rescaled),\n","                                        validation_data=test_dataset_rescaled,\n","                                        validation_steps=len(test_dataset_rescaled),\n","                                        callbacks=[create_tensorboard_callback(\"TesorFlow_Hub\",\"resNet_model\")]\n","                                        )\n"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHozH7vp6cu8","executionInfo":{"status":"ok","timestamp":1760348010466,"user_tz":-180,"elapsed":119,"user":{"displayName":"Moges Tesema","userId":"14633968793904231207"}},"outputId":"92e11b1c-3d7f-4d7c-927d-c7d7b238ad96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rpg54uyngyon"},"outputs":[],"source":["resNet_model.save(\"resNet_trained_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvC75zO-hzR3"},"outputs":[],"source":["from google.colab import files\n","files.download(\"resNet_trained_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKyxp8FFLw_C"},"outputs":[],"source":["resNet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daS1lFA3_Ue0"},"outputs":[],"source":["\n","\n","# Step 3: Wrap the SavedModel in a Keras Layer\n","class EfficientNetLayer(keras.layers.Layer):\n","    def __init__(self, efficientNet_feature_extractor_url, **kwargs):\n","        super().__init__(**kwargs)\n","        # create the hub layer inside init\n","        self.efficientNet_feature_extractor_url = efficientNet_feature_extractor_url\n","        self.efficientNet_feature_extractor = hub.KerasLayer(efficientNet_feature_extractor_url)\n","\n","    def call(self, inputs):\n","        return self.efficientNet_feature_extractor(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"efficientNet_feature_extractor_url\": self.efficientNet_feature_extractor_url\n","        })\n","        return config\n","\n","# Step 4: Build Sequential model\n","num_classes = 10\n","\n","model = keras.Sequential([\n","    keras.Input(shape=(224, 224, 3)),  # input layer\n","    EfficientNetLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"),\n","\n","    # keras.layers.Dropout(0.5),  # regularization\n","    keras.layers.Dense(num_classes, activation='softmax')  # classifier\n","])\n","\n","model.layers[0].efficientNet_feature_extractor.trainable = False # Freeze already learned patterns\n","# Step 5: Compile the model\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K52hD2uiKfJ4"},"outputs":[],"source":["model_weights = model.get_weights()\n","len(model_weights)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ccoipOOT8bk9"},"outputs":[],"source":["efficientNet_history = model.fit(train_dataset_10_percent_rescaled,\n","          epochs=5,\n","          steps_per_epoch=len(train_dataset_10_percent_rescaled),\n","          validation_data=test_dataset_rescaled,\n","          validation_steps=len(test_dataset_rescaled),\n","          callbacks=[create_tensorboard_callback(dir_name=\"Tensorflow_Hub\",experiment_name=\"EffiecientNet\")]\n","          )"]},{"cell_type":"markdown","metadata":{"id":"fG_DUtUgYFF5"},"source":["## Visualize the pre-trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMlRWm5tKZpG"},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","plot_model(model,show_shapes=True,expand_nested=True,show_layer_names=True)"]},{"cell_type":"markdown","metadata":{"id":"cjVnVvEXYNFL"},"source":["### Internal Archticture of EfficientNetBO Neural network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8z44Q58LcZi"},"outputs":[],"source":["from tensorflow.keras.applications import EfficientNetB0\n","\n","feature_extractor = EfficientNetB0(\n","    include_top=False, weights='imagenet', pooling='avg', input_shape=(224,224,3)\n",")\n","# feature_extractor.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGDXnh2dLvF7"},"outputs":[],"source":["# plot_model(feature_extractor,show_shapes=True,expand_nested=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4Sqa0B56XeL"},"outputs":[],"source":["import tensorflow as tf\n","\n","import tensorflow_hub as hub\n","num_classes = 10\n","m = tf.keras.Sequential([\n","    hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1\",\n","                   trainable=False),  # Can be True, see below.\n","    tf.keras.layers.Dense(num_classes, activation='softmax')\n","])\n","m.build([None, 224, 224, 3])  # Batch input shape.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0BckTdKX_Xm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBiUlIAnHhB8"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"vnc2TEhEHHQU"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1YiqKTwLGJvml5BfqidQKtRy0V1jDz5NL","authorship_tag":"ABX9TyPjpbiwVPMFwt+CIGWkgxa5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}