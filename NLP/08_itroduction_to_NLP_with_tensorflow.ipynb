{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20d771b",
   "metadata": {
    "papermill": {
     "duration": 0.005837,
     "end_time": "2025-10-28T08:34:22.359328",
     "exception": false,
     "start_time": "2025-10-28T08:34:22.353491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction to NLP Fundematals in TensorFlow\n",
    "NLP has the goal of deriving information out of natural language(could be sequences text or speech)\n",
    "Another common term for NLP problems is sequence to squence problems(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348b9dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:22.370447Z",
     "iopub.status.busy": "2025-10-28T08:34:22.369785Z",
     "iopub.status.idle": "2025-10-28T08:34:22.512071Z",
     "shell.execute_reply": "2025-10-28T08:34:22.511401Z"
    },
    "papermill": {
     "duration": 0.148972,
     "end_time": "2025-10-28T08:34:22.513317",
     "exception": false,
     "start_time": "2025-10-28T08:34:22.364345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-cd2e686f-93e2-c689-f5f1-745c37140da5)\r\n",
      "GPU 1: Tesla T4 (UUID: GPU-377f1ba6-4bc4-fdd1-eb1e-76e4d4f2c53b)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c4456",
   "metadata": {
    "papermill": {
     "duration": 0.004691,
     "end_time": "2025-10-28T08:34:22.523059",
     "exception": false,
     "start_time": "2025-10-28T08:34:22.518368",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14529ea3",
   "metadata": {
    "papermill": {
     "duration": 0.004598,
     "end_time": "2025-10-28T08:34:22.532498",
     "exception": false,
     "start_time": "2025-10-28T08:34:22.527900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57b807c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:22.543319Z",
     "iopub.status.busy": "2025-10-28T08:34:22.542873Z",
     "iopub.status.idle": "2025-10-28T08:34:22.835735Z",
     "shell.execute_reply": "2025-10-28T08:34:22.835039Z"
    },
    "papermill": {
     "duration": 0.299479,
     "end_time": "2025-10-28T08:34:22.836795",
     "exception": false,
     "start_time": "2025-10-28T08:34:22.537316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-28 08:34:22--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 10246 (10K) [text/plain]\r\n",
      "Saving to: ‘helper_functions.py’\r\n",
      "\r\n",
      "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2025-10-28 08:34:22 (85.0 MB/s) - ‘helper_functions.py’ saved [10246/10246]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ebaf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:22.847716Z",
     "iopub.status.busy": "2025-10-28T08:34:22.847475Z",
     "iopub.status.idle": "2025-10-28T08:34:45.544444Z",
     "shell.execute_reply": "2025-10-28T08:34:45.543778Z"
    },
    "papermill": {
     "duration": 22.703823,
     "end_time": "2025-10-28T08:34:45.545766",
     "exception": false,
     "start_time": "2025-10-28T08:34:22.841943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 08:34:25.945678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761640466.359121      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761640466.493647      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import create_tensorboard_callback,unzip_data,plot_loss_curves,compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbcb359",
   "metadata": {
    "papermill": {
     "duration": 0.00518,
     "end_time": "2025-10-28T08:34:45.556310",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.551130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get a text dataset\n",
    "the dataset we're going to be using is Kaggle's introduction to NLP dataset(text samples of tweets labelled as diaster or not diaster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2771972e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.567516Z",
     "iopub.status.busy": "2025-10-28T08:34:45.566686Z",
     "iopub.status.idle": "2025-10-28T08:34:45.786278Z",
     "shell.execute_reply": "2025-10-28T08:34:45.785487Z"
    },
    "papermill": {
     "duration": 0.226403,
     "end_time": "2025-10-28T08:34:45.787518",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.561115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-28 08:34:45--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.207, 209.85.200.207, 142.250.125.207, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.207|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 607343 (593K) [application/zip]\r\n",
      "Saving to: ‘nlp_getting_started.zip’\r\n",
      "\r\n",
      "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \r\n",
      "\r\n",
      "2025-10-28 08:34:45 (108 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7507c8f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.798879Z",
     "iopub.status.busy": "2025-10-28T08:34:45.798652Z",
     "iopub.status.idle": "2025-10-28T08:34:45.814990Z",
     "shell.execute_reply": "2025-10-28T08:34:45.814507Z"
    },
    "papermill": {
     "duration": 0.023331,
     "end_time": "2025-10-28T08:34:45.816058",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.792727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8461c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.827152Z",
     "iopub.status.busy": "2025-10-28T08:34:45.826472Z",
     "iopub.status.idle": "2025-10-28T08:34:45.830241Z",
     "shell.execute_reply": "2025-10-28T08:34:45.829510Z"
    },
    "papermill": {
     "duration": 0.010301,
     "end_time": "2025-10-28T08:34:45.831359",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.821058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7532f33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.842258Z",
     "iopub.status.busy": "2025-10-28T08:34:45.842018Z",
     "iopub.status.idle": "2025-10-28T08:34:45.888299Z",
     "shell.execute_reply": "2025-10-28T08:34:45.887713Z"
    },
    "papermill": {
     "duration": 0.053193,
     "end_time": "2025-10-28T08:34:45.889462",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.836269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "def56af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.900450Z",
     "iopub.status.busy": "2025-10-28T08:34:45.900237Z",
     "iopub.status.idle": "2025-10-28T08:34:45.923839Z",
     "shell.execute_reply": "2025-10-28T08:34:45.923075Z"
    },
    "papermill": {
     "duration": 0.030383,
     "end_time": "2025-10-28T08:34:45.924911",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.894528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca43f296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.935868Z",
     "iopub.status.busy": "2025-10-28T08:34:45.935676Z",
     "iopub.status.idle": "2025-10-28T08:34:45.945643Z",
     "shell.execute_reply": "2025-10-28T08:34:45.945116Z"
    },
    "papermill": {
     "duration": 0.016805,
     "end_time": "2025-10-28T08:34:45.946808",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.930003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30bd65c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.957748Z",
     "iopub.status.busy": "2025-10-28T08:34:45.957569Z",
     "iopub.status.idle": "2025-10-28T08:34:45.964755Z",
     "shell.execute_reply": "2025-10-28T08:34:45.964139Z"
    },
    "papermill": {
     "duration": 0.013992,
     "end_time": "2025-10-28T08:34:45.965867",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.951875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382ef0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.977748Z",
     "iopub.status.busy": "2025-10-28T08:34:45.977255Z",
     "iopub.status.idle": "2025-10-28T08:34:45.983879Z",
     "shell.execute_reply": "2025-10-28T08:34:45.983360Z"
    },
    "papermill": {
     "duration": 0.013491,
     "end_time": "2025-10-28T08:34:45.984831",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.971340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does the tesst dataframe look like\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a99d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:45.996703Z",
     "iopub.status.busy": "2025-10-28T08:34:45.996275Z",
     "iopub.status.idle": "2025-10-28T08:34:46.007949Z",
     "shell.execute_reply": "2025-10-28T08:34:46.007419Z"
    },
    "papermill": {
     "duration": 0.018685,
     "end_time": "2025-10-28T08:34:46.008928",
     "exception": false,
     "start_time": "2025-10-28T08:34:45.990243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476d1fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.020616Z",
     "iopub.status.busy": "2025-10-28T08:34:46.020109Z",
     "iopub.status.idle": "2025-10-28T08:34:46.024077Z",
     "shell.execute_reply": "2025-10-28T08:34:46.023562Z"
    },
    "papermill": {
     "duration": 0.010821,
     "end_time": "2025-10-28T08:34:46.025082",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.014261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df),len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8165b0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.037530Z",
     "iopub.status.busy": "2025-10-28T08:34:46.036985Z",
     "iopub.status.idle": "2025-10-28T08:34:46.046936Z",
     "shell.execute_reply": "2025-10-28T08:34:46.046102Z"
    },
    "papermill": {
     "duration": 0.017125,
     "end_time": "2025-10-28T08:34:46.048096",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.030971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: 1 (real diaster)\n",
      "Text:\n",
      "The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/bKsYymvIsg #GN\n",
      "\n",
      "____________________ \n",
      "\n",
      "target: 1 (real diaster)\n",
      "Text:\n",
      "???? #Krefeld: the incident happened in a chemical industry park! Emergency operations underway! A building reportly collapsed! @cnnbrk @ntvde\n",
      "\n",
      "____________________ \n",
      "\n",
      "target: 1 (real diaster)\n",
      "Text:\n",
      "Û÷Faceless body belonged to my sisterÛª: #Hiroshima #Nagasaki #nuke survivors recall horrors 70 years on ÛÓ RT News http://t.co/918EQmTkrL\n",
      "\n",
      "____________________ \n",
      "\n",
      "target: 0 (not real diaster)\n",
      "Text:\n",
      "Me trying to look cute wen crush is passing by ... http://t.co/Z87zMi3Ozs\n",
      "\n",
      "____________________ \n",
      "\n",
      "target: 0 (not real diaster)\n",
      "Text:\n",
      "my brain id about to explode lmao\n",
      "\n",
      "____________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0,len(train_df)-5)\n",
    "for row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
    "    _,text,target = row \n",
    "    print(f\"target: {target}\",\"(real diaster)\" if target > 0 else \"(not real diaster)\" )\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(10*\"__\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1433f6",
   "metadata": {
    "papermill": {
     "duration": 0.005373,
     "end_time": "2025-10-28T08:34:46.058971",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.053598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split data into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3887791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.070680Z",
     "iopub.status.busy": "2025-10-28T08:34:46.070490Z",
     "iopub.status.idle": "2025-10-28T08:34:46.097533Z",
     "shell.execute_reply": "2025-10-28T08:34:46.097022Z"
    },
    "papermill": {
     "duration": 0.034156,
     "end_time": "2025-10-28T08:34:46.098632",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.064476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0526e826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.110302Z",
     "iopub.status.busy": "2025-10-28T08:34:46.110097Z",
     "iopub.status.idle": "2025-10-28T08:34:46.115064Z",
     "shell.execute_reply": "2025-10-28T08:34:46.114520Z"
    },
    "papermill": {
     "duration": 0.011938,
     "end_time": "2025-10-28T08:34:46.116013",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.104075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                           test_size=0.1,\n",
    "                                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813a86cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.127700Z",
     "iopub.status.busy": "2025-10-28T08:34:46.127504Z",
     "iopub.status.idle": "2025-10-28T08:34:46.131700Z",
     "shell.execute_reply": "2025-10-28T08:34:46.131164Z"
    },
    "papermill": {
     "duration": 0.011321,
     "end_time": "2025-10-28T08:34:46.132766",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.121445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences),len(train_labels),len(val_sentences),len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a07285b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.144533Z",
     "iopub.status.busy": "2025-10-28T08:34:46.144335Z",
     "iopub.status.idle": "2025-10-28T08:34:46.148873Z",
     "shell.execute_reply": "2025-10-28T08:34:46.148137Z"
    },
    "papermill": {
     "duration": 0.011617,
     "end_time": "2025-10-28T08:34:46.149952",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.138335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first ten samples\n",
    "train_sentences[:10],train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f13f7",
   "metadata": {
    "papermill": {
     "duration": 0.005687,
     "end_time": "2025-10-28T08:34:46.161630",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.155943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Converting text into number, machine learning don't know text.\n",
    "when dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
    "There are a few ways to do this, namely:\n",
    "* *Tokenization* - direct mapping of token (a token could be a word, a character or in between) to number.\n",
    "* *Embedding* - Create a matrix of feature vector for each token ( the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468f895",
   "metadata": {
    "papermill": {
     "duration": 0.005668,
     "end_time": "2025-10-28T08:34:46.173081",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.167413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Text vecorization(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c67adb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.186244Z",
     "iopub.status.busy": "2025-10-28T08:34:46.185452Z",
     "iopub.status.idle": "2025-10-28T08:34:46.265725Z",
     "shell.execute_reply": "2025-10-28T08:34:46.264972Z"
    },
    "papermill": {
     "duration": 0.088037,
     "end_time": "2025-10-28T08:34:46.266941",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.178904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab12029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:46.279437Z",
     "iopub.status.busy": "2025-10-28T08:34:46.279202Z",
     "iopub.status.idle": "2025-10-28T08:34:47.898443Z",
     "shell.execute_reply": "2025-10-28T08:34:47.897581Z"
    },
    "papermill": {
     "duration": 1.626824,
     "end_time": "2025-10-28T08:34:47.899645",
     "exception": false,
     "start_time": "2025-10-28T08:34:46.272821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761640487.852577      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1761640487.853282      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=None, # how many word in the vocablary (automatically add <OOV>\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None, # create groups of n-words\n",
    "                                    output_mode=\"int\", # how to map token to number\n",
    "                                    output_sequence_length=None ,# how long do you want your sequence to be\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96bb96fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:47.913024Z",
     "iopub.status.busy": "2025-10-28T08:34:47.912509Z",
     "iopub.status.idle": "2025-10-28T08:34:47.923494Z",
     "shell.execute_reply": "2025-10-28T08:34:47.922953Z"
    },
    "papermill": {
     "duration": 0.018673,
     "end_time": "2025-10-28T08:34:47.924405",
     "exception": false,
     "start_time": "2025-10-28T08:34:47.905732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.901036345059115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the average number of tokens(words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences]))/len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c522360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:47.936764Z",
     "iopub.status.busy": "2025-10-28T08:34:47.936587Z",
     "iopub.status.idle": "2025-10-28T08:34:47.939836Z",
     "shell.execute_reply": "2025-10-28T08:34:47.939320Z"
    },
    "papermill": {
     "duration": 0.010585,
     "end_time": "2025-10-28T08:34:47.940729",
     "exception": false,
     "start_time": "2025-10-28T08:34:47.930144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup  text vectorization variables\n",
    "max_vocab_length =10000 # max number of words to have in our vocablary\n",
    "max_length = 15 # max lenght our sequences will be ( e.g how many words from a tweet does a model see?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b4c5cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:47.953406Z",
     "iopub.status.busy": "2025-10-28T08:34:47.952837Z",
     "iopub.status.idle": "2025-10-28T08:34:47.959911Z",
     "shell.execute_reply": "2025-10-28T08:34:47.959211Z"
    },
    "papermill": {
     "duration": 0.014463,
     "end_time": "2025-10-28T08:34:47.960960",
     "exception": false,
     "start_time": "2025-10-28T08:34:47.946497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b78bfac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:47.973304Z",
     "iopub.status.busy": "2025-10-28T08:34:47.972779Z",
     "iopub.status.idle": "2025-10-28T08:34:48.203437Z",
     "shell.execute_reply": "2025-10-28T08:34:48.202589Z"
    },
    "papermill": {
     "duration": 0.238234,
     "end_time": "2025-10-28T08:34:48.204869",
     "exception": false,
     "start_time": "2025-10-28T08:34:47.966635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training sentence\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b68c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:48.217942Z",
     "iopub.status.busy": "2025-10-28T08:34:48.217465Z",
     "iopub.status.idle": "2025-10-28T08:34:49.812614Z",
     "shell.execute_reply": "2025-10-28T08:34:49.811796Z"
    },
    "papermill": {
     "duration": 1.602877,
     "end_time": "2025-10-28T08:34:49.813798",
     "exception": false,
     "start_time": "2025-10-28T08:34:48.210921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03bebb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:49.827024Z",
     "iopub.status.busy": "2025-10-28T08:34:49.826474Z",
     "iopub.status.idle": "2025-10-28T08:34:49.863830Z",
     "shell.execute_reply": "2025-10-28T08:34:49.863090Z"
    },
    "papermill": {
     "duration": 0.044865,
     "end_time": "2025-10-28T08:34:49.864952",
     "exception": false,
     "start_time": "2025-10-28T08:34:49.820087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " this is about to be a bomb ass firework picture http://t.co/lr4BTvuEoM \n",
      "\n",
      "Vectorized Version: [  19    9   54    5   21    3  108  227    1 1380    1    0    0    0\n",
      "    0] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
       "array([  19,    9,   54,    5,   21,    3,  108,  227,    1, 1380,    1,\n",
       "          0,    0,    0,    0])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentece from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n {random_sentence} \\n\\nVectorized Version: {text_vectorizer(random_sentence)} \")\n",
    "text_vectorizer(random_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dc79760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:49.878833Z",
     "iopub.status.busy": "2025-10-28T08:34:49.878126Z",
     "iopub.status.idle": "2025-10-28T08:34:49.892613Z",
     "shell.execute_reply": "2025-10-28T08:34:49.892025Z"
    },
    "papermill": {
     "duration": 0.022335,
     "end_time": "2025-10-28T08:34:49.893620",
     "exception": false,
     "start_time": "2025-10-28T08:34:49.871285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
       "array([2718,   22,    2,  149, 1102,    4, 5214, 5214,    1,    1,    0,\n",
       "          0,    0,    0,    0])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if token is a sentence have the same int value across different sentences\n",
    "sample_sentence_two = \"schools are the best Western in Lit lit litterally.. LiTTErALLy..\"\n",
    "text_vectorizer(sample_sentence_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "165e41f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:49.906681Z",
     "iopub.status.busy": "2025-10-28T08:34:49.906130Z",
     "iopub.status.idle": "2025-10-28T08:34:49.931764Z",
     "shell.execute_reply": "2025-10-28T08:34:49.931238Z"
    },
    "papermill": {
     "duration": 0.03308,
     "end_time": "2025-10-28T08:34:49.932767",
     "exception": false,
     "start_time": "2025-10-28T08:34:49.899687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'],\n",
       " 10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in vocabulary\n",
    "top_5_words = words_in_vocab[:5] # get the most common word\n",
    "bottom_5_words = words_in_vocab[-5:] # get the least common word\n",
    "top_5_words,bottom_5_words,len(words_in_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa49c29",
   "metadata": {
    "papermill": {
     "duration": 0.005957,
     "end_time": "2025-10-28T08:34:49.944979",
     "exception": false,
     "start_time": "2025-10-28T08:34:49.939022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating and Embedding using an Embedding Layer\n",
    "To make our embedding, we going to use tensorflow embedding layer\n",
    "The parameters we care most about for our embedding layer:\n",
    "* `input_dim` = the size of our vocabulary\n",
    "* `output_dim` = the size of the output embedding vector,for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
    "*  `input_length` = length of the sequences being passed to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4ff6941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:49.957909Z",
     "iopub.status.busy": "2025-10-28T08:34:49.957703Z",
     "iopub.status.idle": "2025-10-28T08:34:49.962904Z",
     "shell.execute_reply": "2025-10-28T08:34:49.962204Z"
    },
    "papermill": {
     "duration": 0.012967,
     "end_time": "2025-10-28T08:34:49.964081",
     "exception": false,
     "start_time": "2025-10-28T08:34:49.951114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    " from tensorflow.keras import layers\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                            output_dim=128,\n",
    "                             input_length=max_length\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "377ccd71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:49.977270Z",
     "iopub.status.busy": "2025-10-28T08:34:49.976848Z",
     "iopub.status.idle": "2025-10-28T08:34:50.718593Z",
     "shell.execute_reply": "2025-10-28T08:34:50.717934Z"
    },
    "papermill": {
     "duration": 0.749458,
     "end_time": "2025-10-28T08:34:50.719755",
     "exception": false,
     "start_time": "2025-10-28T08:34:49.970297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: \n",
      "i blaze jays fuck the dutch slave trade. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
       " array([   8,  749, 3723,  349,    2, 2484, 8420, 7420,    0,    0,    0,\n",
       "           0,    0,    0,    0])>,\n",
       " <tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n",
       " array([[ 0.00890214, -0.00968239,  0.04006113, ...,  0.02444724,\n",
       "         -0.03097405,  0.03766466],\n",
       "        [-0.04287779,  0.01170005,  0.01082375, ..., -0.03158657,\n",
       "         -0.02600386,  0.03525509],\n",
       "        [-0.0140693 ,  0.00701234,  0.041036  , ..., -0.01645536,\n",
       "         -0.03971409, -0.01663401],\n",
       "        ...,\n",
       "        [ 0.03146468, -0.01183371,  0.03785906, ..., -0.02791339,\n",
       "          0.02644673,  0.03310514],\n",
       "        [ 0.03146468, -0.01183371,  0.03785906, ..., -0.02791339,\n",
       "          0.02644673,  0.03310514],\n",
       "        [ 0.03146468, -0.01183371,  0.03785906, ..., -0.02791339,\n",
       "          0.02644673,  0.03310514]], dtype=float32)>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"original text: \\n{random_sentence} \")\n",
    "random_sentence_vectorized = text_vectorizer(random_sentence)\n",
    "sample_embed = embedding(random_sentence_vectorized)\n",
    "random_sentence_vectorized,sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebaa7592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T08:34:50.735526Z",
     "iopub.status.busy": "2025-10-28T08:34:50.734876Z",
     "iopub.status.idle": "2025-10-28T08:34:50.745394Z",
     "shell.execute_reply": "2025-10-28T08:34:50.744660Z"
    },
    "papermill": {
     "duration": 0.019749,
     "end_time": "2025-10-28T08:34:50.746442",
     "exception": false,
     "start_time": "2025-10-28T08:34:50.726693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 0.00890214, -0.00968239,  0.04006113, -0.01475555,  0.04018278,\n",
       "         0.04354868,  0.02493853,  0.01482353, -0.02612062,  0.02262304,\n",
       "         0.03203391,  0.04728675, -0.01785696,  0.00997829,  0.03664703,\n",
       "         0.02142585, -0.04920781, -0.04717436, -0.04319462, -0.02637791,\n",
       "         0.02204419, -0.03594813, -0.01887835,  0.02218213, -0.02859349,\n",
       "         0.01025492,  0.02550676, -0.02063497,  0.01515073, -0.01725298,\n",
       "        -0.01736519, -0.04280512, -0.00236605, -0.04551083,  0.01478605,\n",
       "         0.04072926, -0.03690739,  0.03558452,  0.02867431, -0.00926601,\n",
       "        -0.01252756,  0.04814238,  0.04243939,  0.0492976 , -0.04130797,\n",
       "         0.04967836,  0.04785136, -0.01032759,  0.01624349,  0.04150525,\n",
       "         0.04691931, -0.02032307,  0.01510243,  0.04972846, -0.04392854,\n",
       "         0.03411725,  0.0231438 ,  0.01149331,  0.0210004 ,  0.0448053 ,\n",
       "         0.01009492, -0.04925275, -0.01135585, -0.00435268,  0.01387974,\n",
       "        -0.00979788,  0.02634777,  0.00545436, -0.01996313, -0.03159168,\n",
       "         0.01817193, -0.04242826,  0.03531231, -0.03761876,  0.04352545,\n",
       "         0.03299009, -0.01711646,  0.01371166, -0.00966983,  0.02982351,\n",
       "         0.02706328,  0.03209846,  0.03100698, -0.03442134,  0.04641843,\n",
       "        -0.00684142,  0.04674374, -0.03375719, -0.02545503,  0.01623119,\n",
       "         0.04128294,  0.04413379, -0.0306461 , -0.02155089, -0.04794371,\n",
       "        -0.0032515 , -0.01737815, -0.04469467, -0.03403685, -0.03817387,\n",
       "        -0.04622557,  0.03849603,  0.03421007,  0.0206535 ,  0.01118539,\n",
       "         0.03280384, -0.04339582,  0.04908352, -0.03550256, -0.03983287,\n",
       "        -0.0472964 ,  0.02249325, -0.04027389, -0.00828964, -0.02628211,\n",
       "        -0.004475  , -0.02159823, -0.02325457, -0.00945174,  0.04816551,\n",
       "        -0.00870112,  0.01974152, -0.03580747, -0.00624914,  0.03187361,\n",
       "         0.02444724, -0.03097405,  0.03766466], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out a single token's embedding\n",
    "sample_embed[0], sample_embed[0].shape,random_sentence_vectorized[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282885",
   "metadata": {
    "papermill": {
     "duration": 0.006301,
     "end_time": "2025-10-28T08:34:50.759065",
     "exception": false,
     "start_time": "2025-10-28T08:34:50.752764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modeling a text dataset (running a series of experiment)\n",
    "Now we've a got way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
    "we'll start with a baseline and move on from there.\n",
    "\n",
    "* Model 0: Naive Bayes(baseline)\n",
    "* Model 1: Feed-Forwared neural Network(dense Model)\n",
    "* Model 2: LSTM model(RNN)\n",
    "* Model 3: GRU model(RNN)\n",
    "* Model 4: Bidirectional-LSTM model(RNN)\n",
    "* Model 5:1D Convolutional Neural Network(CNN)\n",
    "* Model 6: TensorFlow Hub pretrained Feature Extractor(using transofer learning for NLP)\n",
    "* Model 7: saem as model 6 with 10% of training data\n",
    "\n",
    "  How we are going to approach all of these?\n",
    "\n",
    "  Use the standard steps in modelling with tensorflow:\n",
    "  * Create a model\n",
    "  * Build a model\n",
    "  * Fit a model\n",
    "  * Evaluate a model\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90f1c9",
   "metadata": {
    "papermill": {
     "duration": 0.006071,
     "end_time": "2025-10-28T08:34:50.771457",
     "exception": false,
     "start_time": "2025-10-28T08:34:50.765386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model 0: Getting a baseline \n",
    "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiment to build on"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.565204,
   "end_time": "2025-10-28T08:34:53.882595",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-28T08:34:17.317391",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
