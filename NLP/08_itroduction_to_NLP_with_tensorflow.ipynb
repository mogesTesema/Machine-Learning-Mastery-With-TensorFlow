{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1497,"sourceType":"modelInstanceVersion","modelInstanceId":1265,"modelId":191}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to NLP Fundematals in TensorFlow\nNLP has the goal of deriving information out of natural language(could be sequences text or speech)\nAnother common term for NLP problems is sequence to squence problems(seq2seq)","metadata":{}},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:23:53.841800Z","iopub.execute_input":"2025-10-31T09:23:53.842046Z","iopub.status.idle":"2025-10-31T09:23:53.993280Z","shell.execute_reply.started":"2025-10-31T09:23:53.842021Z","shell.execute_reply":"2025-10-31T09:23:53.992317Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Get helper functions","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:51:37.295054Z","iopub.execute_input":"2025-10-31T12:51:37.295346Z","iopub.status.idle":"2025-10-31T12:51:37.607015Z","shell.execute_reply.started":"2025-10-31T12:51:37.295323Z","shell.execute_reply":"2025-10-31T12:51:37.605884Z"}},"outputs":[{"name":"stdout","text":"--2025-10-31 12:51:37--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: ‘helper_functions.py.1’\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n\n2025-10-31 12:51:37 (41.6 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from helper_functions import create_tensorboard_callback,unzip_data,plot_loss_curves,compare_historys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:51:41.585851Z","iopub.execute_input":"2025-10-31T12:51:41.586831Z","iopub.status.idle":"2025-10-31T12:51:41.592032Z","shell.execute_reply.started":"2025-10-31T12:51:41.586795Z","shell.execute_reply":"2025-10-31T12:51:41.590852Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"## Get a text dataset\nthe dataset we're going to be using is Kaggle's introduction to NLP dataset(text samples of tweets labelled as diaster or not diaster).","metadata":{}},{"cell_type":"code","source":"!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:51:45.171416Z","iopub.execute_input":"2025-10-31T12:51:45.171858Z","iopub.status.idle":"2025-10-31T12:51:46.169509Z","shell.execute_reply.started":"2025-10-31T12:51:45.171833Z","shell.execute_reply":"2025-10-31T12:51:46.168519Z"}},"outputs":[{"name":"stdout","text":"--2025-10-31 12:51:45--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 172.217.218.207, 173.194.69.207, 142.250.153.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|172.217.218.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 607343 (593K) [application/zip]\nSaving to: ‘nlp_getting_started.zip’\n\nnlp_getting_started 100%[===================>] 593.11K  1.19MB/s    in 0.5s    \n\n2025-10-31 12:51:46 (1.19 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# unzip the data\nunzip_data(\"nlp_getting_started.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:51:52.721499Z","iopub.execute_input":"2025-10-31T12:51:52.721867Z","iopub.status.idle":"2025-10-31T12:51:52.741995Z","shell.execute_reply.started":"2025-10-31T12:51:52.721831Z","shell.execute_reply":"2025-10-31T12:51:52.741001Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:51:55.246365Z","iopub.execute_input":"2025-10-31T12:51:55.246665Z","iopub.status.idle":"2025-10-31T12:51:55.252133Z","shell.execute_reply.started":"2025-10-31T12:51:55.246646Z","shell.execute_reply":"2025-10-31T12:51:55.250825Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_df = pd.read_csv(\"train.csv\")\ntest_df = pd.read_csv(\"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:51:57.537511Z","iopub.execute_input":"2025-10-31T12:51:57.538429Z","iopub.status.idle":"2025-10-31T12:51:57.598622Z","shell.execute_reply.started":"2025-10-31T12:51:57.538399Z","shell.execute_reply":"2025-10-31T12:51:57.597748Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:00.346341Z","iopub.execute_input":"2025-10-31T12:52:00.346654Z","iopub.status.idle":"2025-10-31T12:52:00.377834Z","shell.execute_reply.started":"2025-10-31T12:52:00.346635Z","shell.execute_reply":"2025-10-31T12:52:00.376919Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# shuffle training dataframe\ntrain_df_shuffled = train_df.sample(frac=1,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:05.915207Z","iopub.execute_input":"2025-10-31T12:52:05.915558Z","iopub.status.idle":"2025-10-31T12:52:05.927217Z","shell.execute_reply.started":"2025-10-31T12:52:05.915530Z","shell.execute_reply":"2025-10-31T12:52:05.926155Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"train_df_shuffled.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:08.733190Z","iopub.execute_input":"2025-10-31T12:52:08.733956Z","iopub.status.idle":"2025-10-31T12:52:08.744368Z","shell.execute_reply.started":"2025-10-31T12:52:08.733922Z","shell.execute_reply":"2025-10-31T12:52:08.743218Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"        id      keyword               location  \\\n2644  3796  destruction                    NaN   \n2227  3185       deluge                    NaN   \n5448  7769       police                     UK   \n132    191   aftershock                    NaN   \n6845  9810       trauma  Montgomery County, MD   \n\n                                                   text  target  \n2644  So you have a new weapon that can cause un-ima...       1  \n2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n132   Aftershock back to school kick off was great. ...       0  \n6845  in response to trauma Children of Addicts deve...       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2644</th>\n      <td>3796</td>\n      <td>destruction</td>\n      <td>NaN</td>\n      <td>So you have a new weapon that can cause un-ima...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2227</th>\n      <td>3185</td>\n      <td>deluge</td>\n      <td>NaN</td>\n      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5448</th>\n      <td>7769</td>\n      <td>police</td>\n      <td>UK</td>\n      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>191</td>\n      <td>aftershock</td>\n      <td>NaN</td>\n      <td>Aftershock back to school kick off was great. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6845</th>\n      <td>9810</td>\n      <td>trauma</td>\n      <td>Montgomery County, MD</td>\n      <td>in response to trauma Children of Addicts deve...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# what does the tesst dataframe look like\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:13.379994Z","iopub.execute_input":"2025-10-31T12:52:13.380808Z","iopub.status.idle":"2025-10-31T12:52:13.390592Z","shell.execute_reply.started":"2025-10-31T12:52:13.380776Z","shell.execute_reply":"2025-10-31T12:52:13.389551Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# how many examples of each class?\ntrain_df.target.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:17.366768Z","iopub.execute_input":"2025-10-31T12:52:17.367415Z","iopub.status.idle":"2025-10-31T12:52:17.381904Z","shell.execute_reply.started":"2025-10-31T12:52:17.367389Z","shell.execute_reply":"2025-10-31T12:52:17.380895Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"target\n0    4342\n1    3271\nName: count, dtype: int64"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"len(train_df),len(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:24:07.993870Z","iopub.execute_input":"2025-10-31T09:24:07.994057Z","iopub.status.idle":"2025-10-31T09:24:08.003408Z","shell.execute_reply.started":"2025-10-31T09:24:07.994042Z","shell.execute_reply":"2025-10-31T09:24:08.002779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's visualize some random training examples\nimport random\nrandom_index = random.randint(0,len(train_df)-5)\nfor row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n    _,text,target = row \n    print(f\"target: {target}\",\"(real diaster)\" if target > 0 else \"(not real diaster)\" )\n    print(f\"Text:\\n{text}\\n\")\n    print(10*\"__\",\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:24.053740Z","iopub.execute_input":"2025-10-31T12:52:24.054166Z","iopub.status.idle":"2025-10-31T12:52:24.067074Z","shell.execute_reply.started":"2025-10-31T12:52:24.054138Z","shell.execute_reply":"2025-10-31T12:52:24.065917Z"}},"outputs":[{"name":"stdout","text":"target: 1 (real diaster)\nText:\nÛÏ@FDNY: This morning #FDNY responded to a sinkhole in #Brooklyn. Units remain on-scene with @NYCBuildings &amp; others. http://t.co/M78ir0IK01Û\n\n____________________ \n\ntarget: 1 (real diaster)\nText:\nTop insurer blasts lack of Australian Govt action on disaster mitigation http://t.co/sDgOUtWNtb via @smh\n\n____________________ \n\ntarget: 0 (not real diaster)\nText:\nMere sight of a gun makes police ÛÒ and public ÛÒ more aggressive experts say http://t.co/N4NEUIyt2k\n\n____________________ \n\ntarget: 1 (real diaster)\nText:\nArmageddon https://t.co/uCSUDk3q1d\n\n____________________ \n\ntarget: 0 (not real diaster)\nText:\nThat moth that held me hostage yesterday has been chilling on the bathroom windowsill all day and I'm not okay with this\n\n____________________ \n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"### Split data into training and validation datasets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:28.653174Z","iopub.execute_input":"2025-10-31T12:52:28.653499Z","iopub.status.idle":"2025-10-31T12:52:28.675158Z","shell.execute_reply.started":"2025-10-31T12:52:28.653474Z","shell.execute_reply":"2025-10-31T12:52:28.674078Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n                                                                            train_df_shuffled[\"target\"].to_numpy(),\n                                                                           test_size=0.1,\n                                                                           random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:30.531418Z","iopub.execute_input":"2025-10-31T12:52:30.531792Z","iopub.status.idle":"2025-10-31T12:52:30.539154Z","shell.execute_reply.started":"2025-10-31T12:52:30.531757Z","shell.execute_reply":"2025-10-31T12:52:30.538104Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"len(train_sentences),len(train_labels),len(val_sentences),len(val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:33.867384Z","iopub.execute_input":"2025-10-31T12:52:33.867738Z","iopub.status.idle":"2025-10-31T12:52:33.874449Z","shell.execute_reply.started":"2025-10-31T12:52:33.867707Z","shell.execute_reply":"2025-10-31T12:52:33.873480Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"(6851, 6851, 762, 762)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# check the first ten samples\ntrain_sentences[:10],train_labels[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:37.507322Z","iopub.execute_input":"2025-10-31T12:52:37.507669Z","iopub.status.idle":"2025-10-31T12:52:37.514378Z","shell.execute_reply.started":"2025-10-31T12:52:37.507643Z","shell.execute_reply":"2025-10-31T12:52:37.513233Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n        'Imagine getting flattened by Kurt Zouma',\n        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n        'destroy the free fandom honestly',\n        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n       dtype=object),\n array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"## Converting text into number, machine learning don't know text.\nwhen dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\nThere are a few ways to do this, namely:\n* *Tokenization* - direct mapping of token (a token could be a word, a character or in between) to number.\n* *Embedding* - Create a matrix of feature vector for each token ( the size of the feature vector can be defined and this embedding can be learned)","metadata":{}},{"cell_type":"markdown","source":"### Text vecorization(tokenization)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import TextVectorization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:44.400111Z","iopub.execute_input":"2025-10-31T12:52:44.400798Z","iopub.status.idle":"2025-10-31T12:52:44.411436Z","shell.execute_reply.started":"2025-10-31T12:52:44.400762Z","shell.execute_reply":"2025-10-31T12:52:44.410570Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"text_vectorizer = TextVectorization(max_tokens=None, # how many word in the vocablary (automatically add <OOV>\n                                    standardize=\"lower_and_strip_punctuation\",\n                                    split=\"whitespace\",\n                                    ngrams=None, # create groups of n-words\n                                    output_mode=\"int\", # how to map token to number\n                                    output_sequence_length=None ,# how long do you want your sequence to be\n                                    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:46.573255Z","iopub.execute_input":"2025-10-31T12:52:46.574058Z","iopub.status.idle":"2025-10-31T12:52:46.596109Z","shell.execute_reply.started":"2025-10-31T12:52:46.574027Z","shell.execute_reply":"2025-10-31T12:52:46.595286Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# find the average number of tokens(words) in the training tweets\nround(sum([len(i.split()) for i in train_sentences]))/len(train_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:49.421963Z","iopub.execute_input":"2025-10-31T12:52:49.422261Z","iopub.status.idle":"2025-10-31T12:52:49.437267Z","shell.execute_reply.started":"2025-10-31T12:52:49.422242Z","shell.execute_reply":"2025-10-31T12:52:49.436394Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"14.901036345059115"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# setup  text vectorization variables\nmax_vocab_length =10000 # max number of words to have in our vocablary\nmax_length = 15 # max lenght our sequences will be ( e.g how many words from a tweet does a model see?)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:53.093565Z","iopub.execute_input":"2025-10-31T12:52:53.093944Z","iopub.status.idle":"2025-10-31T12:52:53.098776Z","shell.execute_reply.started":"2025-10-31T12:52:53.093920Z","shell.execute_reply":"2025-10-31T12:52:53.097606Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n                                    output_mode=\"int\",\n                                    output_sequence_length=max_length\n                                   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:52:58.889285Z","iopub.execute_input":"2025-10-31T12:52:58.890022Z","iopub.status.idle":"2025-10-31T12:52:58.899606Z","shell.execute_reply.started":"2025-10-31T12:52:58.889992Z","shell.execute_reply":"2025-10-31T12:52:58.898798Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Fit the text vectorizer to the training sentence\ntext_vectorizer.adapt(train_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:04.838757Z","iopub.execute_input":"2025-10-31T12:53:04.839498Z","iopub.status.idle":"2025-10-31T12:53:04.921434Z","shell.execute_reply.started":"2025-10-31T12:53:04.839468Z","shell.execute_reply":"2025-10-31T12:53:04.920511Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Create a sample sentence and tokenize it\nsample_sentence = \"There's a flood in my street!\"\ntext_vectorizer([sample_sentence])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:08.500365Z","iopub.execute_input":"2025-10-31T12:53:08.501288Z","iopub.status.idle":"2025-10-31T12:53:08.533828Z","shell.execute_reply.started":"2025-10-31T12:53:08.501256Z","shell.execute_reply":"2025-10-31T12:53:08.532881Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\narray([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]])>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"# Choose a random sentece from the training dataset and tokenize it\nrandom_sentence = random.choice(train_sentences)\nprint(f\"Original text:\\n {random_sentence} \\n\\nVectorized Version: {text_vectorizer(random_sentence)} \")\ntext_vectorizer(random_sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:12.233669Z","iopub.execute_input":"2025-10-31T12:53:12.234655Z","iopub.status.idle":"2025-10-31T12:53:12.271209Z","shell.execute_reply.started":"2025-10-31T12:53:12.234624Z","shell.execute_reply":"2025-10-31T12:53:12.270301Z"}},"outputs":[{"name":"stdout","text":"Original text:\n Enugu Government to demolish illegal structures at International Conference Centre http://t.co/7K5SHaiqIw \n\nVectorized Version: [1297  547    5  516 1836 2276   17 1199 1877 1036    1    0    0    0\n    0] \n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(15,), dtype=int64, numpy=\narray([1297,  547,    5,  516, 1836, 2276,   17, 1199, 1877, 1036,    1,\n          0,    0,    0,    0])>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"# check if token is a sentence have the same int value across different sentences\nsample_sentence_two = \"schools are the best Western in Lit lit litterally.. LiTTErALLy..\"\ntext_vectorizer(sample_sentence_two)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:16.421967Z","iopub.execute_input":"2025-10-31T12:53:16.422289Z","iopub.status.idle":"2025-10-31T12:53:16.441726Z","shell.execute_reply.started":"2025-10-31T12:53:16.422266Z","shell.execute_reply":"2025-10-31T12:53:16.440757Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(15,), dtype=int64, numpy=\narray([2718,   22,    2,  149, 1102,    4, 5214, 5214,    1,    1,    0,\n          0,    0,    0,    0])>"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"# Get the unique words in the vocabulary\nwords_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in vocabulary\ntop_5_words = words_in_vocab[:5] # get the most common word\nbottom_5_words = words_in_vocab[-5:] # get the least common word\ntop_5_words,bottom_5_words,len(words_in_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:19.467205Z","iopub.execute_input":"2025-10-31T12:53:19.467532Z","iopub.status.idle":"2025-10-31T12:53:19.508140Z","shell.execute_reply.started":"2025-10-31T12:53:19.467506Z","shell.execute_reply":"2025-10-31T12:53:19.507133Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"(['', '[UNK]', 'the', 'a', 'in'],\n ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'],\n 10000)"},"metadata":{}}],"execution_count":59},{"cell_type":"markdown","source":"### Creating and Embedding using an Embedding Layer\nTo make our embedding, we going to use tensorflow embedding layer\nThe parameters we care most about for our embedding layer:\n* `input_dim` = the size of our vocabulary\n* `output_dim` = the size of the output embedding vector,for example, a value of 100 would mean each token gets represented by a vector 100 long\n*  `input_length` = length of the sequences being passed to the embedding layer","metadata":{}},{"cell_type":"code","source":" from tensorflow.keras import layers\nembedding = layers.Embedding(input_dim=max_vocab_length,\n                            output_dim=128,\n                             input_length=max_length\n                            )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:23.589397Z","iopub.execute_input":"2025-10-31T12:53:23.590139Z","iopub.status.idle":"2025-10-31T12:53:23.597951Z","shell.execute_reply.started":"2025-10-31T12:53:23.590103Z","shell.execute_reply":"2025-10-31T12:53:23.596917Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# Get a random sentence from the training set\nrandom_sentence = random.choice(train_sentences)\nprint(f\"original text: \\n{random_sentence} \")\nrandom_sentence_vectorized = text_vectorizer(random_sentence)\nsample_embed = embedding(random_sentence_vectorized)\nrandom_sentence_vectorized,sample_embed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:29.146255Z","iopub.execute_input":"2025-10-31T12:53:29.146578Z","iopub.status.idle":"2025-10-31T12:53:29.203492Z","shell.execute_reply.started":"2025-10-31T12:53:29.146553Z","shell.execute_reply":"2025-10-31T12:53:29.202486Z"}},"outputs":[{"name":"stdout","text":"original text: \nInvestigators shift focus to cause of fatal Waimate fire http://t.co/aDSvDpNP3r \n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"(<tf.Tensor: shape=(15,), dtype=int64, numpy=\n array([ 420,  988, 2109,    5,  257,    6,  163, 2615,   42,    1,    0,\n           0,    0,    0,    0])>,\n <tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n array([[ 4.7201406e-02, -9.5920675e-03, -2.4193002e-02, ...,\n         -9.9213608e-03, -4.3546535e-02,  1.7108891e-02],\n        [-4.4974852e-02,  4.2800616e-02,  3.7815463e-02, ...,\n          3.9716411e-02,  2.4020281e-02, -1.1399437e-02],\n        [-2.7111148e-02, -1.8554293e-02, -4.5135714e-02, ...,\n          4.5683395e-02,  5.2236021e-05,  8.9861751e-03],\n        ...,\n        [ 2.6647855e-02,  2.7680922e-02, -1.4325418e-02, ...,\n         -2.2269094e-02,  1.0610722e-02,  2.9167797e-02],\n        [ 2.6647855e-02,  2.7680922e-02, -1.4325418e-02, ...,\n         -2.2269094e-02,  1.0610722e-02,  2.9167797e-02],\n        [ 2.6647855e-02,  2.7680922e-02, -1.4325418e-02, ...,\n         -2.2269094e-02,  1.0610722e-02,  2.9167797e-02]], dtype=float32)>)"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"# check out a single token's embedding\nsample_embed[0], sample_embed[0].shape,random_sentence_vectorized[14]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:34.541224Z","iopub.execute_input":"2025-10-31T12:53:34.541552Z","iopub.status.idle":"2025-10-31T12:53:34.555275Z","shell.execute_reply.started":"2025-10-31T12:53:34.541525Z","shell.execute_reply":"2025-10-31T12:53:34.554012Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n array([ 0.04720141, -0.00959207, -0.024193  , -0.01261927, -0.01031259,\n        -0.02490903,  0.01632405, -0.02368134,  0.01414777,  0.00334474,\n         0.03338731,  0.01977942, -0.01160901,  0.04723107,  0.00597067,\n         0.00070716, -0.00610645,  0.02543307,  0.04448214,  0.01200265,\n         0.04859145,  0.01230508, -0.04115115, -0.02860166, -0.04703654,\n        -0.03888854, -0.01194274,  0.00793676, -0.01742103,  0.0146677 ,\n        -0.03307382, -0.00890846,  0.04887294, -0.04852685,  0.03917069,\n        -0.02458229, -0.00862589,  0.0269776 ,  0.0083824 , -0.01838181,\n         0.00584043, -0.0486443 , -0.03473888, -0.02024984,  0.00895911,\n        -0.00814612,  0.01972857,  0.01198785, -0.00893375, -0.02231455,\n         0.01002989,  0.01747633,  0.04375396, -0.04298608, -0.0422945 ,\n         0.01861909, -0.01085585, -0.04459664, -0.01454009, -0.0486149 ,\n        -0.047469  , -0.0344394 ,  0.04315026, -0.01709048, -0.0061091 ,\n         0.04523739,  0.00038446, -0.01655384, -0.00495727,  0.02988612,\n         0.04011041,  0.04994014,  0.00713874,  0.04515028, -0.03424223,\n         0.01325264, -0.00150742, -0.02703736, -0.04573863, -0.01053611,\n        -0.01554399,  0.03741309, -0.02715911, -0.04585082,  0.04991895,\n         0.03482063,  0.04828535, -0.01360774,  0.02225507, -0.01124962,\n         0.01199405,  0.01085197,  0.038337  , -0.03918229, -0.01873885,\n        -0.03185548, -0.03269221,  0.02761884, -0.03675947,  0.01407852,\n        -0.04795197,  0.04132373,  0.04904448,  0.02753084,  0.00534813,\n         0.01764531, -0.04313552, -0.04333991, -0.03860655,  0.00873504,\n         0.03288993,  0.00276736, -0.04166098, -0.01479774,  0.01992405,\n        -0.03925503, -0.0439813 ,  0.02257366,  0.00393555, -0.03279309,\n        -0.02881739, -0.01715889,  0.0135937 , -0.04467952,  0.02598869,\n        -0.00992136, -0.04354654,  0.01710889], dtype=float32)>,\n TensorShape([128]),\n <tf.Tensor: shape=(), dtype=int64, numpy=0>)"},"metadata":{}}],"execution_count":62},{"cell_type":"markdown","source":"## Modeling a text dataset (running a series of experiment)\nNow we've a got way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\nwe'll start with a baseline and move on from there.\n\n* Model 0: Naive Bayes(baseline)\n* Model 1: Feed-Forwared neural Network(dense Model)\n* Model 2: LSTM model(RNN)\n* Model 3: GRU model(RNN)\n* Model 4: Bidirectional-LSTM model(RNN)\n* Model 5:1D Convolutional Neural Network(CNN)\n* Model 6: TensorFlow Hub pretrained Feature Extractor(using transofer learning for NLP)\n* Model 7: same as model 6 with 10% of training data\n\n  How we are going to approach all of these?\n\n  Use the standard steps in modelling with tensorflow:\n  * Create a model\n  * Build a model\n  * Fit a model\n  * Evaluate a model\n  ","metadata":{}},{"cell_type":"markdown","source":"### Model 0: Getting a baseline \nAs with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiment to build on","metadata":{}},{"cell_type":"code","source":"# !pip install scikit-learn\nimport sklearn\nprint(sklearn.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:37:53.785766Z","iopub.execute_input":"2025-10-31T09:37:53.786308Z","iopub.status.idle":"2025-10-31T09:37:53.790747Z","shell.execute_reply.started":"2025-10-31T09:37:53.786284Z","shell.execute_reply":"2025-10-31T09:37:53.789718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:37:55.559158Z","iopub.execute_input":"2025-10-31T09:37:55.559428Z","iopub.status.idle":"2025-10-31T09:37:55.563428Z","shell.execute_reply.started":"2025-10-31T09:37:55.559410Z","shell.execute_reply":"2025-10-31T09:37:55.562688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create tokenization and modelling pipeline \nmodel_0 = Pipeline([\n    (\"tfidf\",TfidfVectorizer()), # convert words into numbers using tfidf\n    (\"clf\",MultinomialNB()) # model the text\n])\n\n# Fit the pipeline to the training data\nmodel_0_history = model_0.fit(train_sentences,train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:01.001041Z","iopub.execute_input":"2025-10-31T09:38:01.001633Z","iopub.status.idle":"2025-10-31T09:38:01.123106Z","shell.execute_reply.started":"2025-10-31T09:38:01.001610Z","shell.execute_reply":"2025-10-31T09:38:01.122567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_0_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:04.489756Z","iopub.execute_input":"2025-10-31T09:38:04.490571Z","iopub.status.idle":"2025-10-31T09:38:04.496587Z","shell.execute_reply.started":"2025-10-31T09:38:04.490539Z","shell.execute_reply":"2025-10-31T09:38:04.495800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate our baseline model\nbaseline_score = model_0.score(val_sentences,val_labels)\nbaseline_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:06.972268Z","iopub.execute_input":"2025-10-31T09:38:06.972539Z","iopub.status.idle":"2025-10-31T09:38:06.990185Z","shell.execute_reply.started":"2025-10-31T09:38:06.972520Z","shell.execute_reply":"2025-10-31T09:38:06.989511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Our baseline model achievs an accuracy of: {baseline_score}\")\ntrain_df.target.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:09.830537Z","iopub.execute_input":"2025-10-31T09:38:09.830891Z","iopub.status.idle":"2025-10-31T09:38:09.837607Z","shell.execute_reply.started":"2025-10-31T09:38:09.830873Z","shell.execute_reply":"2025-10-31T09:38:09.836730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# make predictions\nbaseline_preds = model_0.predict(val_sentences)\nbaseline_preds[:2],val_sentences[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:13.396562Z","iopub.execute_input":"2025-10-31T09:38:13.397052Z","iopub.status.idle":"2025-10-31T09:38:13.414472Z","shell.execute_reply.started":"2025-10-31T09:38:13.397032Z","shell.execute_reply":"2025-10-31T09:38:13.413620Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating an evaluation function for our model experiments\nwe could evaluate all of our model's predictions with different metrics every time,however, this will be cumbersome and could easily be fixed using function\nLet's create one to compare our model's predictions with the truth labels using the following metrics:\n* Accuracy\n* Percision\n* Recall\n* F1-score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,precision_recall_fscore_support\ndef calculate_results(y_true, y_preds):\n    \"\"\"\n    Calculates model accuracy, recall, precision and f1-score\n    of a binary classification model.\n    \"\"\"\n    model_accuracy = accuracy_score(y_true, y_preds) * 100\n    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(\n        y_true, y_preds, average=\"weighted\"\n    )\n    model_results = {\n        \"accuracy\": model_accuracy,\n        \"precision\": model_precision,\n        \"recall\": model_recall,\n        \"f1\": model_f1,\n    }\n    return model_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:52.715979Z","iopub.execute_input":"2025-10-31T12:53:52.716324Z","iopub.status.idle":"2025-10-31T12:53:52.722045Z","shell.execute_reply.started":"2025-10-31T12:53:52.716299Z","shell.execute_reply":"2025-10-31T12:53:52.720918Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"baseline_results = calculate_results(y_true=val_labels,y_preds=baseline_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:20.690937Z","iopub.execute_input":"2025-10-31T09:38:20.691731Z","iopub.status.idle":"2025-10-31T09:38:20.698803Z","shell.execute_reply.started":"2025-10-31T09:38:20.691704Z","shell.execute_reply":"2025-10-31T09:38:20.698013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:23.075763Z","iopub.execute_input":"2025-10-31T09:38:23.076385Z","iopub.status.idle":"2025-10-31T09:38:23.081184Z","shell.execute_reply.started":"2025-10-31T09:38:23.076362Z","shell.execute_reply":"2025-10-31T09:38:23.080388Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model 1: A simple dense model","metadata":{}},{"cell_type":"code","source":"# Create a directory to save tensorboard logs\nSAVE_DIR = \"model_logs\"\n# Bild model with the Functional API\nfrom tensorflow.keras import layers\ninputs = layers.Input(shape=(),dtype=tf.string,name=\"input_layer\")\nx = text_vectorizer(inputs) # turn the input text into number\nx = embedding(x) # create an embedding of the numberized inputs\nx = layers.GlobalAveragePooling1D(name=\"globalAverage_layer\")(x)\n# x = layers.Flatten()(x)\noutputs = layers.Dense(1,activation=\"sigmoid\",name=\"output_layer\")(x)\nmodel_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:53:59.856288Z","iopub.execute_input":"2025-10-31T12:53:59.856824Z","iopub.status.idle":"2025-10-31T12:53:59.882583Z","shell.execute_reply.started":"2025-10-31T12:53:59.856795Z","shell.execute_reply":"2025-10-31T12:53:59.881760Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"model_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:30.797300Z","iopub.execute_input":"2025-10-31T09:38:30.797901Z","iopub.status.idle":"2025-10-31T09:38:30.812084Z","shell.execute_reply.started":"2025-10-31T09:38:30.797880Z","shell.execute_reply":"2025-10-31T09:38:30.811392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compile the model\nmodel_1.compile(loss=\"binary_crossentropy\",\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:34.249022Z","iopub.execute_input":"2025-10-31T09:38:34.249740Z","iopub.status.idle":"2025-10-31T09:38:34.257722Z","shell.execute_reply.started":"2025-10-31T09:38:34.249715Z","shell.execute_reply":"2025-10-31T09:38:34.257158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the model\nmodel_1_history = model_1.fit(x=train_sentences,\n                             y=train_labels,\n                             epochs=5,\n                             validation_data=(val_sentences,val_labels),\n                             callbacks=[create_tensorboard_callback(\"TensorBoard\",\"model_1_dense\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:36.228334Z","iopub.execute_input":"2025-10-31T09:38:36.229083Z","iopub.status.idle":"2025-10-31T09:38:43.859206Z","shell.execute_reply.started":"2025-10-31T09:38:36.229055Z","shell.execute_reply":"2025-10-31T09:38:43.858519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_loss_curves(model_1_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:24:21.899550Z","iopub.execute_input":"2025-10-31T09:24:21.899813Z","iopub.status.idle":"2025-10-31T09:24:22.397310Z","shell.execute_reply.started":"2025-10-31T09:24:21.899775Z","shell.execute_reply":"2025-10-31T09:24:22.396557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_1.evaluate(val_sentences,val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:44.408896Z","iopub.execute_input":"2025-10-31T09:38:44.409407Z","iopub.status.idle":"2025-10-31T09:38:44.567505Z","shell.execute_reply.started":"2025-10-31T09:38:44.409386Z","shell.execute_reply":"2025-10-31T09:38:44.566928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_1_pred_probs = model_1.predict(val_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:47.644656Z","iopub.execute_input":"2025-10-31T09:38:47.645305Z","iopub.status.idle":"2025-10-31T09:38:48.075108Z","shell.execute_reply.started":"2025-10-31T09:38:47.645279Z","shell.execute_reply":"2025-10-31T09:38:48.074555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_1_pred_probs.shape,val_sentences[:5],model_1_pred_probs[:5]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:50.107072Z","iopub.execute_input":"2025-10-31T09:38:50.107866Z","iopub.status.idle":"2025-10-31T09:38:50.112923Z","shell.execute_reply.started":"2025-10-31T09:38:50.107840Z","shell.execute_reply":"2025-10-31T09:38:50.112159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# convert model prediction probablity to a label format\nmodel_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\nmodel_1_preds[:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:53.675333Z","iopub.execute_input":"2025-10-31T09:38:53.675610Z","iopub.status.idle":"2025-10-31T09:38:53.683779Z","shell.execute_reply.started":"2025-10-31T09:38:53.675590Z","shell.execute_reply":"2025-10-31T09:38:53.682995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_1_results = calculate_results(y_true=val_labels,y_preds=model_1_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:38:59.605646Z","iopub.execute_input":"2025-10-31T09:38:59.606251Z","iopub.status.idle":"2025-10-31T09:38:59.613153Z","shell.execute_reply.started":"2025-10-31T09:38:59.606228Z","shell.execute_reply":"2025-10-31T09:38:59.612629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_1_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:39:01.497642Z","iopub.execute_input":"2025-10-31T09:39:01.497917Z","iopub.status.idle":"2025-10-31T09:39:01.502966Z","shell.execute_reply.started":"2025-10-31T09:39:01.497899Z","shell.execute_reply":"2025-10-31T09:39:01.502137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:39:09.011009Z","iopub.execute_input":"2025-10-31T09:39:09.011506Z","iopub.status.idle":"2025-10-31T09:39:09.016323Z","shell.execute_reply.started":"2025-10-31T09:39:09.011482Z","shell.execute_reply":"2025-10-31T09:39:09.015540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nnp.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:24:23.182206Z","iopub.execute_input":"2025-10-31T09:24:23.182404Z","iopub.status.idle":"2025-10-31T09:24:23.190588Z","shell.execute_reply.started":"2025-10-31T09:24:23.182389Z","shell.execute_reply":"2025-10-31T09:24:23.189776Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing Learned Embeddings","metadata":{}},{"cell_type":"code","source":"# Get the vocabulary from the text vectorization layer\nwords_in_vocab = text_vectorizer.get_vocabulary()\nlen(words_in_vocab), words_in_vocab[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:39:11.912958Z","iopub.execute_input":"2025-10-31T09:39:11.913655Z","iopub.status.idle":"2025-10-31T09:39:11.946656Z","shell.execute_reply.started":"2025-10-31T09:39:11.913629Z","shell.execute_reply":"2025-10-31T09:39:11.946029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model 1 summary\nmodel_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:24:23.227826Z","iopub.execute_input":"2025-10-31T09:24:23.228081Z","iopub.status.idle":"2025-10-31T09:24:23.243774Z","shell.execute_reply.started":"2025-10-31T09:24:23.228064Z","shell.execute_reply":"2025-10-31T09:24:23.243170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get the weight metrics of embedding layer\n# (these are the numberical representations of each token in our training data, which have been learned for 5 epochs)\nprint(f\"total parameter of embedding weights: {len(embedding.get_weights()[0])}\")\nembed_weights = model_1.get_layer(\"embedding_5\").get_weights()[0]\nprint(embed_weights[:20])\nprint(f\"shape of embedding: {embed_weights.shape} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:40:40.025237Z","iopub.execute_input":"2025-10-31T09:40:40.025512Z","iopub.status.idle":"2025-10-31T09:40:40.036172Z","shell.execute_reply.started":"2025-10-31T09:40:40.025493Z","shell.execute_reply":"2025-10-31T09:40:40.035470Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we've got the embedding matrix our mdoel has learned to represent our tokens, let's see how we can visualize it.\nto do so, TensorFlow as a handy tool called projector.\nand tensorflow alos has an incredible guide on word embeddings themselves.","metadata":{}},{"cell_type":"code","source":"words_in_vocab[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:04.010902Z","iopub.execute_input":"2025-10-31T09:41:04.011465Z","iopub.status.idle":"2025-10-31T09:41:04.016321Z","shell.execute_reply.started":"2025-10-31T09:41:04.011441Z","shell.execute_reply":"2025-10-31T09:41:04.015538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create embedding files from tensorflow word embedding docs\nimport io\nout_v = io.open('vectors.tsv', 'w', encoding='utf-8')\nout_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n\nfor index, word in enumerate(words_in_vocab):\n  if index == 0:\n    continue  # skip 0, it's padding.\n  vec = embed_weights[index]\n  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n  out_m.write(word + \"\\n\")\nout_v.close()\nout_m.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:07.768197Z","iopub.execute_input":"2025-10-31T09:41:07.768958Z","iopub.status.idle":"2025-10-31T09:41:08.454670Z","shell.execute_reply.started":"2025-10-31T09:41:07.768932Z","shell.execute_reply":"2025-10-31T09:41:08.453855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorboard\nprint(tensorboard.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:12.654964Z","iopub.execute_input":"2025-10-31T09:41:12.655324Z","iopub.status.idle":"2025-10-31T09:41:12.659529Z","shell.execute_reply.started":"2025-10-31T09:41:12.655302Z","shell.execute_reply":"2025-10-31T09:41:12.658800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#docs_infra: no_execute\n%load_ext tensorboard\n%tensorboard --logdir /kaggle/working/TensorBoard/model_1_dense","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:16.576510Z","iopub.execute_input":"2025-10-31T09:41:16.577094Z","iopub.status.idle":"2025-10-31T09:41:23.614753Z","shell.execute_reply.started":"2025-10-31T09:41:16.577069Z","shell.execute_reply":"2025-10-31T09:41:23.614149Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Recurrent Neural Networks (RNN's)\nRNN's are useful sequence data.\n\nThe promise of a recurrent neural network is to use the ***`representation`*** of a previous input to aid the representation of a later input.","metadata":{}},{"cell_type":"markdown","source":"### model 2: LSTM\nLSTM = long short-term memory (one of the most popular LSTM cells)\nOUr structure of an RNN typically looks like this:\n```\nInput(text) -> Tokenize -> Embedding -> Layers(RNNs/Dense) -> Output(label probability)\n```","metadata":{}},{"cell_type":"code","source":"# Create an LSTM model\nfrom tensorflow.keras import layers\ninputs = layers.Input(shape=(1,),dtype=\"string\")\nx = text_vectorizer(inputs)\n# print(x.shape)\nx = embedding(x)\n# print(x.shape)\n# x = layers.LSTM(units=64,return_sequences=True)(x)\n# print(x.shape)\nx = layers.LSTM(64)(x)\n# print(x.shape)\n# x = layers.Dense(64,activation=\"relu\")(x)\noutputs = layers.Dense(1,activation=\"sigmoid\")(x)\nmodel_2 = tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:31.352184Z","iopub.execute_input":"2025-10-31T09:41:31.352747Z","iopub.status.idle":"2025-10-31T09:41:31.477572Z","shell.execute_reply.started":"2025-10-31T09:41:31.352722Z","shell.execute_reply":"2025-10-31T09:41:31.477013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_2.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:34.978690Z","iopub.execute_input":"2025-10-31T09:41:34.979304Z","iopub.status.idle":"2025-10-31T09:41:34.993793Z","shell.execute_reply.started":"2025-10-31T09:41:34.979283Z","shell.execute_reply":"2025-10-31T09:41:34.993049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_2.compile(loss=\"binary_crossentropy\",\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:41:38.938566Z","iopub.execute_input":"2025-10-31T09:41:38.939273Z","iopub.status.idle":"2025-10-31T09:41:38.947266Z","shell.execute_reply.started":"2025-10-31T09:41:38.939246Z","shell.execute_reply":"2025-10-31T09:41:38.946504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_2_history = model_2.fit(train_sentences,\n                             train_labels,\n                             epochs=5,\n                             validation_data=(val_sentences,val_labels),\n                             callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_2_LSTM\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:05.199289Z","iopub.execute_input":"2025-10-31T09:42:05.199573Z","iopub.status.idle":"2025-10-31T09:42:12.440061Z","shell.execute_reply.started":"2025-10-31T09:42:05.199553Z","shell.execute_reply":"2025-10-31T09:42:12.439516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# make prediction with LSTM model\nmodel_2_pred_probs = model_2.predict(val_sentences)\nmodel_2_pred_probs[:10]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:19.036980Z","iopub.execute_input":"2025-10-31T09:42:19.037650Z","iopub.status.idle":"2025-10-31T09:42:19.681182Z","shell.execute_reply.started":"2025-10-31T09:42:19.037625Z","shell.execute_reply":"2025-10-31T09:42:19.680434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\nmodel_2_preds[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:25.986192Z","iopub.execute_input":"2025-10-31T09:42:25.986882Z","iopub.status.idle":"2025-10-31T09:42:25.993984Z","shell.execute_reply.started":"2025-10-31T09:42:25.986856Z","shell.execute_reply":"2025-10-31T09:42:25.993200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_labels[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:29.143954Z","iopub.execute_input":"2025-10-31T09:42:29.144548Z","iopub.status.idle":"2025-10-31T09:42:29.149549Z","shell.execute_reply.started":"2025-10-31T09:42:29.144525Z","shell.execute_reply":"2025-10-31T09:42:29.148768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate model 2 results\nmodel_2_results = calculate_results(y_true=val_labels,y_preds=model_2_preds)\nmodel_2_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:31.352264Z","iopub.execute_input":"2025-10-31T09:42:31.352556Z","iopub.status.idle":"2025-10-31T09:42:31.362240Z","shell.execute_reply.started":"2025-10-31T09:42:31.352535Z","shell.execute_reply":"2025-10-31T09:42:31.361429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:34.429514Z","iopub.execute_input":"2025-10-31T09:42:34.430198Z","iopub.status.idle":"2025-10-31T09:42:34.434572Z","shell.execute_reply.started":"2025-10-31T09:42:34.430175Z","shell.execute_reply":"2025-10-31T09:42:34.433676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from math import e\nprint(e)\ndef tanh_func(z):\n    a = (e**z - e**(-z))/(e**z + e**(-z)) # tensorflow don't know math and python label code durring computational graph, it must be tensorflow optrational for derivation of gradients\n    return a\n    # return (tf.exp(z) - tf.exp(-z)) / (tf.exp(z) + tf.exp(-z))\n    # return tf.math.tanh(z)\ntanh_func(1.)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:37.134775Z","iopub.execute_input":"2025-10-31T09:42:37.135586Z","iopub.status.idle":"2025-10-31T09:42:37.141652Z","shell.execute_reply.started":"2025-10-31T09:42:37.135561Z","shell.execute_reply":"2025-10-31T09:42:37.140864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### build GRU model 3\nAnother popular and effective RNN component is the GRU or gated recurrent unit.\nThe GRU cell has similar features to an LSTM cell but has less parameters.","metadata":{}},{"cell_type":"code","source":"inputs = layers.Input(shape=(1,),dtype=tf.string,name=\"input_layer\")\nx = text_vectorizer(inputs)\nx = embedding(x)\nx = layers.GRU(units=64,activation=tanh_func)(x)\n# x = layers.Lambda(tanh_func)(x)\noutputs = layers.Dense(1,activation=\"sigmoid\",name=\"output_layer\")(x)\nmodel_3 = tf.keras.Model(inputs,outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:45.570001Z","iopub.execute_input":"2025-10-31T09:42:45.570743Z","iopub.status.idle":"2025-10-31T09:42:45.597943Z","shell.execute_reply.started":"2025-10-31T09:42:45.570717Z","shell.execute_reply":"2025-10-31T09:42:45.597419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:47.563690Z","iopub.execute_input":"2025-10-31T09:42:47.564396Z","iopub.status.idle":"2025-10-31T09:42:47.580715Z","shell.execute_reply.started":"2025-10-31T09:42:47.564371Z","shell.execute_reply":"2025-10-31T09:42:47.579955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compile the model\nmodel_3.compile(loss=\"binary_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:51.648037Z","iopub.execute_input":"2025-10-31T09:42:51.648627Z","iopub.status.idle":"2025-10-31T09:42:51.657368Z","shell.execute_reply.started":"2025-10-31T09:42:51.648603Z","shell.execute_reply":"2025-10-31T09:42:51.656637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_history = model_3.fit(train_sentences,\n                             train_labels,\n                             epochs=5,\n                             validation_data=(val_sentences,val_labels),\n                             callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_3_GRU\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:42:53.730646Z","iopub.execute_input":"2025-10-31T09:42:53.731375Z","iopub.status.idle":"2025-10-31T09:43:29.504744Z","shell.execute_reply.started":"2025-10-31T09:42:53.731352Z","shell.execute_reply":"2025-10-31T09:43:29.504165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_loss_curves(model_3_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:29.506399Z","iopub.execute_input":"2025-10-31T09:43:29.506652Z","iopub.status.idle":"2025-10-31T09:43:29.887816Z","shell.execute_reply.started":"2025-10-31T09:43:29.506636Z","shell.execute_reply":"2025-10-31T09:43:29.887107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_pred_probs = model_3.predict(val_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:37.356353Z","iopub.execute_input":"2025-10-31T09:43:37.356854Z","iopub.status.idle":"2025-10-31T09:43:38.396407Z","shell.execute_reply.started":"2025-10-31T09:43:37.356834Z","shell.execute_reply":"2025-10-31T09:43:38.395850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\nmodel_3_preds[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:40.056633Z","iopub.execute_input":"2025-10-31T09:43:40.056899Z","iopub.status.idle":"2025-10-31T09:43:40.064296Z","shell.execute_reply.started":"2025-10-31T09:43:40.056880Z","shell.execute_reply":"2025-10-31T09:43:40.063581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_results = calculate_results(y_true=val_labels,y_preds=model_3_preds)\nmodel_3_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:43.812547Z","iopub.execute_input":"2025-10-31T09:43:43.813019Z","iopub.status.idle":"2025-10-31T09:43:43.821996Z","shell.execute_reply.started":"2025-10-31T09:43:43.812996Z","shell.execute_reply":"2025-10-31T09:43:43.821265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model 4: Bidirectional RNN\nNormal RNN go from left to right (just like you'd read and English sentence), however, a bidirectional RNN goes from right to left as well as left to right.\n","metadata":{}},{"cell_type":"code","source":"# Build a bidirectional RNN in tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import layers\ninputs = layers.Input(shape=(1,),dtype=tf.string)\nx = text_vectorizer(inputs)\nprint(x.shape)\nx = embedding(x)\nprint(x.shape)\n# x = layers.Bidirectional(layers.LSTM(64,return_sequences=True))(x)\n# print(x.shape)\nx = layers.Bidirectional(layers.LSTM(64))(x)\nprint(x.shape)\noutputs = layers.Dense(1,activation=\"sigmoid\")(x)\nmodel_4 = tf.keras.Model(inputs,outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:48.069260Z","iopub.execute_input":"2025-10-31T09:43:48.069941Z","iopub.status.idle":"2025-10-31T09:43:48.122911Z","shell.execute_reply.started":"2025-10-31T09:43:48.069917Z","shell.execute_reply":"2025-10-31T09:43:48.122275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_4.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:52.581913Z","iopub.execute_input":"2025-10-31T09:43:52.582206Z","iopub.status.idle":"2025-10-31T09:43:52.596942Z","shell.execute_reply.started":"2025-10-31T09:43:52.582185Z","shell.execute_reply":"2025-10-31T09:43:52.596419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_4.compile(loss=\"binary_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:56.687537Z","iopub.execute_input":"2025-10-31T09:43:56.688018Z","iopub.status.idle":"2025-10-31T09:43:56.696456Z","shell.execute_reply.started":"2025-10-31T09:43:56.687997Z","shell.execute_reply":"2025-10-31T09:43:56.695836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_4_history = model_4.fit(train_sentences,\n                             train_labels,\n                             epochs=5,\n                             validation_data=(val_sentences,val_labels),\n                             callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_4_bidirectional\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:43:58.772303Z","iopub.execute_input":"2025-10-31T09:43:58.772811Z","iopub.status.idle":"2025-10-31T09:44:11.093924Z","shell.execute_reply.started":"2025-10-31T09:43:58.772791Z","shell.execute_reply":"2025-10-31T09:44:11.093049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_loss_curves(model_4_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:44:16.466387Z","iopub.execute_input":"2025-10-31T09:44:16.467052Z","iopub.status.idle":"2025-10-31T09:44:16.835144Z","shell.execute_reply.started":"2025-10-31T09:44:16.467028Z","shell.execute_reply":"2025-10-31T09:44:16.834443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_4_pred_probs = model_4.predict(val_sentences)\nmodel_4_pred_probs[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:44:23.335788Z","iopub.execute_input":"2025-10-31T09:44:23.336037Z","iopub.status.idle":"2025-10-31T09:44:24.228573Z","shell.execute_reply.started":"2025-10-31T09:44:23.336022Z","shell.execute_reply":"2025-10-31T09:44:24.227759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\nmodel_4_preds[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:44:27.474676Z","iopub.execute_input":"2025-10-31T09:44:27.474945Z","iopub.status.idle":"2025-10-31T09:44:27.482295Z","shell.execute_reply.started":"2025-10-31T09:44:27.474925Z","shell.execute_reply":"2025-10-31T09:44:27.481583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_4_results = calculate_results(y_true=val_labels,y_preds=model_4_preds)\nmodel_4_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T09:44:30.611681Z","iopub.execute_input":"2025-10-31T09:44:30.611948Z","iopub.status.idle":"2025-10-31T09:44:30.620452Z","shell.execute_reply.started":"2025-10-31T09:44:30.611930Z","shell.execute_reply":"2025-10-31T09:44:30.619753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convolutional Neural Network for Text(and other types of sequences)\nWe've used CNNs for images but images are typically 2D (hieght X Widht)... however, ouor text data is 1D.\nPreviously we've Conv2D for our image data but now we're going to use Conv1D.\n\nThe typical structure of a Conv1D model for seqeunces (in our case,text):\n```\nInputs(xtext) -> Toknization -> Embedding -> Layer(s) (typicaly Conv1D and some kind of Pooling layer) -> outputs(Class probability)\n```\n","metadata":{}},{"cell_type":"markdown","source":"### Model 5: Conv1D\n","metadata":{}},{"cell_type":"code","source":"# Test out our embedding layer,Conv1D layer and max Pooling layer\nvectorizer_test = text_vectorizer([\"this is test sentences\"])\nembedding_test = embedding(vectorizer_test)\nconv_1d = layers.Conv1D(filters=32,\n                       kernel_size=5,\n                       activation=\"relu\",\n                       padding=\"valid\")\nconv_1d_output = conv_1d(embedding_test)\nmax_pool = layers.GlobalMaxPool1D()\nmax_pool_output = max_pool(conv_1d_output)\nembedding_test.shape,conv_1d_output.shape,max_pool_output.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:50:35.308147Z","iopub.execute_input":"2025-10-31T12:50:35.308869Z","iopub.status.idle":"2025-10-31T12:50:35.330610Z","shell.execute_reply.started":"2025-10-31T12:50:35.308842Z","shell.execute_reply":"2025-10-31T12:50:35.329294Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/35602688.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test out our embedding layer,Conv1D layer and max Pooling layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectorizer_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"this is test sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0membedding_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m conv_1d = layers.Conv1D(filters=32,\n\u001b[1;32m      5\u001b[0m                        \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'text_vectorizer' is not defined"],"ename":"NameError","evalue":"name 'text_vectorizer' is not defined","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"vectorizer_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:27:46.919385Z","iopub.execute_input":"2025-10-31T10:27:46.919968Z","iopub.status.idle":"2025-10-31T10:27:46.924835Z","shell.execute_reply.started":"2025-10-31T10:27:46.919945Z","shell.execute_reply":"2025-10-31T10:27:46.924173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"voc_words = text_vectorizer.get_vocabulary()\nvoc_words[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:28:36.088699Z","iopub.execute_input":"2025-10-31T10:28:36.089026Z","iopub.status.idle":"2025-10-31T10:28:36.121240Z","shell.execute_reply.started":"2025-10-31T10:28:36.089003Z","shell.execute_reply":"2025-10-31T10:28:36.120596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"voc_words[9]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:36:39.563831Z","iopub.execute_input":"2025-10-31T10:36:39.564603Z","iopub.status.idle":"2025-10-31T10:36:39.569405Z","shell.execute_reply.started":"2025-10-31T10:36:39.564575Z","shell.execute_reply":"2025-10-31T10:36:39.568631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:24:27.033577Z","iopub.execute_input":"2025-10-31T10:24:27.033892Z","iopub.status.idle":"2025-10-31T10:24:27.040222Z","shell.execute_reply.started":"2025-10-31T10:24:27.033872Z","shell.execute_reply":"2025-10-31T10:24:27.039526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conv_1d_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:24:40.742238Z","iopub.execute_input":"2025-10-31T10:24:40.742490Z","iopub.status.idle":"2025-10-31T10:24:40.749410Z","shell.execute_reply.started":"2025-10-31T10:24:40.742474Z","shell.execute_reply":"2025-10-31T10:24:40.748710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_pool_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:26:09.195619Z","iopub.execute_input":"2025-10-31T10:26:09.196242Z","iopub.status.idle":"2025-10-31T10:26:09.201804Z","shell.execute_reply.started":"2025-10-31T10:26:09.196219Z","shell.execute_reply":"2025-10-31T10:26:09.201062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create model 5\nfrom tensorflow.keras import layers\ninputs = layers.Input(shape=(1,),dtype=tf.string,name=\"input_layer\") # make sure you pass dtype string in input layer otherwise it treat as integer and leads to graph excution error.\nx = text_vectorizer(inputs)\nx = embedding(x)\nx = layers.Conv1D(filters=32,\n                 kernel_size=5,\n                 activation=\"relu\",\n                 strides=1,\n                 padding=\"valid\")(x)\nx = layers.GlobalMaxPool1D()(x)\noutputs = layers.Dense(1,activation=\"sigmoid\",name=\"output_layer\")(x)\nmodel_5 = tf.keras.Model(inputs,outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:55:34.113158Z","iopub.execute_input":"2025-10-31T10:55:34.113723Z","iopub.status.idle":"2025-10-31T10:55:34.135247Z","shell.execute_reply.started":"2025-10-31T10:55:34.113699Z","shell.execute_reply":"2025-10-31T10:55:34.134630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_5.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:55:39.081109Z","iopub.execute_input":"2025-10-31T10:55:39.081430Z","iopub.status.idle":"2025-10-31T10:55:39.096578Z","shell.execute_reply.started":"2025-10-31T10:55:39.081409Z","shell.execute_reply":"2025-10-31T10:55:39.095859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_5.compile(loss=\"binary_crossentropy\",\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T11:22:02.393186Z","iopub.execute_input":"2025-10-31T11:22:02.393460Z","iopub.status.idle":"2025-10-31T11:22:02.402046Z","shell.execute_reply.started":"2025-10-31T11:22:02.393441Z","shell.execute_reply":"2025-10-31T11:22:02.401281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compile the model\nmodel_5.fit(train_sentences,\n               train_labels,\n               epochs=5,\n               validation_data=(val_sentences,val_labels),\n               callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_5_Conv1D\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T10:55:46.683913Z","iopub.execute_input":"2025-10-31T10:55:46.684229Z","iopub.status.idle":"2025-10-31T10:55:55.509471Z","shell.execute_reply.started":"2025-10-31T10:55:46.684202Z","shell.execute_reply":"2025-10-31T10:55:55.508814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_sentences[:10],val_labels[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T11:26:16.480966Z","iopub.execute_input":"2025-10-31T11:26:16.481720Z","iopub.status.idle":"2025-10-31T11:26:16.486884Z","shell.execute_reply.started":"2025-10-31T11:26:16.481696Z","shell.execute_reply":"2025-10-31T11:26:16.486241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# val_sentences = tf.constant(val_sentences, dtype=tf.string)\n# val_labels = tf.constant(val_labels, dtype=tf.float32)\n# # \n# model_5.evaluate(val_sentences, val_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T11:35:39.465582Z","iopub.execute_input":"2025-10-31T11:35:39.466168Z","iopub.status.idle":"2025-10-31T11:35:39.469190Z","shell.execute_reply.started":"2025-10-31T11:35:39.466114Z","shell.execute_reply":"2025-10-31T11:35:39.468455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_5_pred_probs = model_5.predict(val_sentences)\nmodel_5_pred_probs[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T11:22:26.542791Z","iopub.execute_input":"2025-10-31T11:22:26.543058Z","iopub.status.idle":"2025-10-31T11:22:27.020240Z","shell.execute_reply.started":"2025-10-31T11:22:26.543038Z","shell.execute_reply":"2025-10-31T11:22:27.019567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\nmodel_5_preds[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T11:22:40.799538Z","iopub.execute_input":"2025-10-31T11:22:40.800021Z","iopub.status.idle":"2025-10-31T11:22:40.807039Z","shell.execute_reply.started":"2025-10-31T11:22:40.799997Z","shell.execute_reply":"2025-10-31T11:22:40.806410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_5_results = calculate_results(y_true=val_labels,y_preds=model_5_preds)\nmodel_5_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T11:36:39.839034Z","iopub.execute_input":"2025-10-31T11:36:39.839596Z","iopub.status.idle":"2025-10-31T11:36:39.849040Z","shell.execute_reply.started":"2025-10-31T11:36:39.839572Z","shell.execute_reply":"2025-10-31T11:36:39.848263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model 6: Tensorflow Hub pretrained sentences Encoder\nNow we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's universal sentence encoder","metadata":{}},{"cell_type":"code","source":"# # from huggingface_hub importing and using model\n# from huggingface_hub import snapshot_download\n# from tensorflow_hub import KerasLayer\n\n# # Download the model locally from Hugging Face\n# model_path = snapshot_download(repo_id=\"Dimitre/universal-sentence-encoder\")\n\n# # Load it as a Keras Layer\n# model = KerasLayer(handle=model_path)\n\n# # Generate embeddings\n# embeddings = model([\n#     \"The quick brown fox jumps over the lazy dog.\",\n#     \"I am a sentence for which I would like to get its embedding.\"\n# ])\n\n# print(embeddings)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:25:00.052913Z","iopub.execute_input":"2025-10-31T12:25:00.053596Z","iopub.status.idle":"2025-10-31T12:25:20.009639Z","shell.execute_reply.started":"2025-10-31T12:25:00.053568Z","shell.execute_reply":"2025-10-31T12:25:20.008510Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0cce57e50804b3cb9fb3fb76fd25b1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"saved_model.pb:   0%|          | 0.00/8.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7aa08a27fc4422b37abbc85afde95c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e6a8ebd33a4f499fef3f7d51cad27a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"variables.index:   0%|          | 0.00/3.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9953eb162a8c482eb7c1591581789d72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10c8d37178ec46e9add0505d4311a00c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"variables/variables.data-00000-of-00001:   0%|          | 0.00/1.03G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19dd1ec138f4e5db1c6562426ebaab7"}},"metadata":{}},{"name":"stdout","text":"tf.Tensor(\n[[-0.03133017 -0.06338634 -0.01607501 ... -0.03242778 -0.0457574\n   0.05370456]\n [ 0.0508086  -0.01652434  0.01573779 ...  0.00976657  0.03170121\n   0.01788118]], shape=(2, 512), dtype=float32)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# import kagglehub\n# from tensorflow_hub import KerasLayer\n\n# # Download latest version\n# path = kagglehub.model_download(\"google/universal-sentence-encoder/tensorFlow2/universal-sentence-encoder\")\n\n# print(\"Path to model files:\", path)\n# model = KerasLayer(path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T12:35:53.473786Z","iopub.execute_input":"2025-10-31T12:35:53.474130Z","iopub.status.idle":"2025-10-31T12:36:02.675570Z","shell.execute_reply.started":"2025-10-31T12:35:53.474110Z","shell.execute_reply":"2025-10-31T12:36:02.674743Z"}},"outputs":[{"name":"stdout","text":"Path to model files: /kaggle/input/universal-sentence-encoder/tensorflow2/universal-sentence-encoder/2\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import tensorflow_hub as hub\n\nmodel = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n                       trainable=False,\n                       input_shape=[],\n                       dtype=tf.string\n                      )\n\nembeddings = model([\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"I am a sentence for which I would like to get its embedding.\"\n])\n\nprint(embeddings) # (2, 512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:01:54.364162Z","iopub.execute_input":"2025-10-31T13:01:54.365118Z","iopub.status.idle":"2025-10-31T13:02:03.966646Z","shell.execute_reply.started":"2025-10-31T13:01:54.365084Z","shell.execute_reply":"2025-10-31T13:02:03.965641Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[-0.03133017 -0.06338634 -0.01607501 ... -0.03242778 -0.0457574\n   0.05370456]\n [ 0.0508086  -0.01652434  0.01573779 ...  0.00976657  0.03170121\n   0.01788118]], shape=(2, 512), dtype=float32)\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"embeded = model([\"hello world\"])\nembeded.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:02:28.144965Z","iopub.execute_input":"2025-10-31T13:02:28.145510Z","iopub.status.idle":"2025-10-31T13:02:28.160449Z","shell.execute_reply.started":"2025-10-31T13:02:28.145475Z","shell.execute_reply":"2025-10-31T13:02:28.159467Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"TensorShape([1, 512])"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"text_vec_test = text_vectorizer(\"hello tensorflow this the embedding pretrained model\")\ntext_vec_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:02:28.162253Z","iopub.execute_input":"2025-10-31T13:02:28.162514Z","iopub.status.idle":"2025-10-31T13:02:28.183214Z","shell.execute_reply.started":"2025-10-31T13:02:28.162494Z","shell.execute_reply":"2025-10-31T13:02:28.182378Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(15,), dtype=int64, numpy=\narray([1400,    1,   19,    2,    1,    1, 3616,    0,    0,    0,    0,\n          0,    0,    0,    0])>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"embeded = embedding(text_vec_test)\nembeded.shape,embeded[:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:02:34.894800Z","iopub.execute_input":"2025-10-31T13:02:34.895704Z","iopub.status.idle":"2025-10-31T13:02:34.907067Z","shell.execute_reply.started":"2025-10-31T13:02:34.895652Z","shell.execute_reply":"2025-10-31T13:02:34.906077Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"(TensorShape([15, 128]),\n <tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n array([[ 0.04106346,  0.01319272,  0.01162927, ..., -0.02430424,\n          0.00630056,  0.03895735],\n        [ 0.02830743,  0.00486987,  0.03268256, ...,  0.0345865 ,\n         -0.04999486, -0.03345146],\n        [-0.02976241, -0.01092074,  0.03112445, ..., -0.00333148,\n          0.04269382, -0.04233369],\n        ...,\n        [ 0.02664785,  0.02768092, -0.01432542, ..., -0.02226909,\n          0.01061072,  0.0291678 ],\n        [ 0.02664785,  0.02768092, -0.01432542, ..., -0.02226909,\n          0.01061072,  0.0291678 ],\n        [ 0.02664785,  0.02768092, -0.01432542, ..., -0.02226909,\n          0.01061072,  0.0291678 ]], dtype=float32)>)"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"from tensorflow.keras import layers\ninputs = layers.Input(shape=(),dtype=tf.string,name=\"input_layer\")\n# x = text_vectorizer(inputs)\n# x = embedding(x)\nx = model(inputs)\noutputs = layers.Dense(1,activation=\"sigmoid\",name=\"output_layer\")(x)\nmodel_6 = tf.keras.Model(inputs,outputs)\nmodel_6.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:02:37.861645Z","iopub.execute_input":"2025-10-31T13:02:37.862033Z","iopub.status.idle":"2025-10-31T13:02:37.890964Z","shell.execute_reply.started":"2025-10-31T13:02:37.862011Z","shell.execute_reply":"2025-10-31T13:02:37.889565Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1522572327.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# x = text_vectorizer(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# x = embedding(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer_11' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_11' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>\n  • training=None"],"ename":"TypeError","evalue":"Exception encountered when calling layer 'keras_layer_11' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_11' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>\n  • training=None","output_type":"error"}],"execution_count":78},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\n\n# ✅ Rename to avoid conflict\nuse_layer = hub.KerasLayer(\n    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n    input_shape=[], dtype=tf.string, trainable=False\n)\n\n# Define the actual model\ninputs = layers.Input(shape=(), dtype=tf.string, name=\"input_layer\")\nx = use_layer(inputs)\noutputs = layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n\nmodel_6 = tf.keras.Model(inputs, outputs)\nmodel_6.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:04:44.952596Z","iopub.execute_input":"2025-10-31T13:04:44.953043Z","iopub.status.idle":"2025-10-31T13:04:53.871272Z","shell.execute_reply.started":"2025-10-31T13:04:44.953015Z","shell.execute_reply":"2025-10-31T13:04:53.869940Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2241993893.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Define the actual model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer_12' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_12' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>\n  • training=None"],"ename":"TypeError","evalue":"Exception encountered when calling layer 'keras_layer_12' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_12' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=input_layer>\n  • training=None","output_type":"error"}],"execution_count":79},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}