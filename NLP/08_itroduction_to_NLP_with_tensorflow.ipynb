{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to NLP Fundematals in TensorFlow\nNLP has the goal of deriving information out of natural language(could be sequences text or speech)\nAnother common term for NLP problems is sequence to squence problems(seq2seq)","metadata":{}},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.220580Z","iopub.execute_input":"2025-10-28T06:45:44.220913Z","iopub.status.idle":"2025-10-28T06:45:44.387153Z","shell.execute_reply.started":"2025-10-28T06:45:44.220888Z","shell.execute_reply":"2025-10-28T06:45:44.386284Z"}},"outputs":[{"name":"stdout","text":"GPU 0: Tesla T4 (UUID: GPU-01edf4ae-6ea0-9d29-499d-94de9a298143)\nGPU 1: Tesla T4 (UUID: GPU-a3a596c8-bd5f-647b-d8e4-8f4d00ea032c)\n","output_type":"stream"}],"execution_count":102},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Get helper functions","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.388730Z","iopub.execute_input":"2025-10-28T06:45:44.389003Z","iopub.status.idle":"2025-10-28T06:45:44.632760Z","shell.execute_reply.started":"2025-10-28T06:45:44.388980Z","shell.execute_reply":"2025-10-28T06:45:44.631873Z"}},"outputs":[{"name":"stdout","text":"--2025-10-28 06:45:44--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: ‘helper_functions.py.3’\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0.001s  \n\n2025-10-28 06:45:44 (14.0 MB/s) - ‘helper_functions.py.3’ saved [10246/10246]\n\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"from helper_functions import create_tensorboard_callback,unzip_data,plot_loss_curves,compare_historys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.633939Z","iopub.execute_input":"2025-10-28T06:45:44.634565Z","iopub.status.idle":"2025-10-28T06:45:44.638482Z","shell.execute_reply.started":"2025-10-28T06:45:44.634533Z","shell.execute_reply":"2025-10-28T06:45:44.637533Z"}},"outputs":[],"execution_count":104},{"cell_type":"markdown","source":"## Get a text dataset\nthe dataset we're going to be using is Kaggle's introduction to NLP dataset(text samples of tweets labelled as diaster or not diaster).","metadata":{}},{"cell_type":"code","source":"!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.640559Z","iopub.execute_input":"2025-10-28T06:45:44.640750Z","iopub.status.idle":"2025-10-28T06:45:44.851629Z","shell.execute_reply.started":"2025-10-28T06:45:44.640735Z","shell.execute_reply":"2025-10-28T06:45:44.850947Z"}},"outputs":[{"name":"stdout","text":"--2025-10-28 06:45:44--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.206.207, 173.194.64.207, 142.251.183.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.206.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 607343 (593K) [application/zip]\nSaving to: ‘nlp_getting_started.zip.3’\n\nnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n\n2025-10-28 06:45:44 (92.0 MB/s) - ‘nlp_getting_started.zip.3’ saved [607343/607343]\n\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"# unzip the data\nunzip_data(\"nlp_getting_started.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.852646Z","iopub.execute_input":"2025-10-28T06:45:44.852952Z","iopub.status.idle":"2025-10-28T06:45:44.869063Z","shell.execute_reply.started":"2025-10-28T06:45:44.852930Z","shell.execute_reply":"2025-10-28T06:45:44.868525Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.869776Z","iopub.execute_input":"2025-10-28T06:45:44.870025Z","iopub.status.idle":"2025-10-28T06:45:44.873296Z","shell.execute_reply.started":"2025-10-28T06:45:44.870011Z","shell.execute_reply":"2025-10-28T06:45:44.872692Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"train_df = pd.read_csv(\"train.csv\")\ntest_df = pd.read_csv(\"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.874019Z","iopub.execute_input":"2025-10-28T06:45:44.874298Z","iopub.status.idle":"2025-10-28T06:45:44.916537Z","shell.execute_reply.started":"2025-10-28T06:45:44.874276Z","shell.execute_reply":"2025-10-28T06:45:44.916009Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.917215Z","iopub.execute_input":"2025-10-28T06:45:44.917682Z","iopub.status.idle":"2025-10-28T06:45:44.926150Z","shell.execute_reply.started":"2025-10-28T06:45:44.917665Z","shell.execute_reply":"2025-10-28T06:45:44.925427Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"# shuffle training dataframe\ntrain_df_shuffled = train_df.sample(frac=1,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.926893Z","iopub.execute_input":"2025-10-28T06:45:44.927055Z","iopub.status.idle":"2025-10-28T06:45:44.941210Z","shell.execute_reply.started":"2025-10-28T06:45:44.927043Z","shell.execute_reply":"2025-10-28T06:45:44.940474Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"train_df_shuffled.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.944135Z","iopub.execute_input":"2025-10-28T06:45:44.944939Z","iopub.status.idle":"2025-10-28T06:45:44.958891Z","shell.execute_reply.started":"2025-10-28T06:45:44.944922Z","shell.execute_reply":"2025-10-28T06:45:44.958070Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"        id      keyword               location  \\\n2644  3796  destruction                    NaN   \n2227  3185       deluge                    NaN   \n5448  7769       police                     UK   \n132    191   aftershock                    NaN   \n6845  9810       trauma  Montgomery County, MD   \n\n                                                   text  target  \n2644  So you have a new weapon that can cause un-ima...       1  \n2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n132   Aftershock back to school kick off was great. ...       0  \n6845  in response to trauma Children of Addicts deve...       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2644</th>\n      <td>3796</td>\n      <td>destruction</td>\n      <td>NaN</td>\n      <td>So you have a new weapon that can cause un-ima...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2227</th>\n      <td>3185</td>\n      <td>deluge</td>\n      <td>NaN</td>\n      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5448</th>\n      <td>7769</td>\n      <td>police</td>\n      <td>UK</td>\n      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>191</td>\n      <td>aftershock</td>\n      <td>NaN</td>\n      <td>Aftershock back to school kick off was great. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6845</th>\n      <td>9810</td>\n      <td>trauma</td>\n      <td>Montgomery County, MD</td>\n      <td>in response to trauma Children of Addicts deve...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"# what does the tesst dataframe look like\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.959777Z","iopub.execute_input":"2025-10-28T06:45:44.960037Z","iopub.status.idle":"2025-10-28T06:45:44.973234Z","shell.execute_reply.started":"2025-10-28T06:45:44.960022Z","shell.execute_reply":"2025-10-28T06:45:44.972540Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"# how many examples of each class?\ntrain_df.target.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.974057Z","iopub.execute_input":"2025-10-28T06:45:44.974300Z","iopub.status.idle":"2025-10-28T06:45:44.986675Z","shell.execute_reply.started":"2025-10-28T06:45:44.974284Z","shell.execute_reply":"2025-10-28T06:45:44.986017Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"target\n0    4342\n1    3271\nName: count, dtype: int64"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"len(train_df),len(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.987394Z","iopub.execute_input":"2025-10-28T06:45:44.987656Z","iopub.status.idle":"2025-10-28T06:45:44.998520Z","shell.execute_reply.started":"2025-10-28T06:45:44.987640Z","shell.execute_reply":"2025-10-28T06:45:44.997938Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"(7613, 3263)"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"# Let's visualize some random training examples\nimport random\nrandom_index = random.randint(0,len(train_df)-5)\nfor row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n    _,text,target = row \n    print(f\"target: {target}\",\"(real diaster)\" if target > 0 else \"(not real diaster)\" )\n    print(f\"Text:\\n{text}\\n\")\n    print(10*\"__\",\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:44.999132Z","iopub.execute_input":"2025-10-28T06:45:44.999349Z","iopub.status.idle":"2025-10-28T06:45:45.014037Z","shell.execute_reply.started":"2025-10-28T06:45:44.999336Z","shell.execute_reply":"2025-10-28T06:45:45.013203Z"}},"outputs":[{"name":"stdout","text":"target: 0 (not real diaster)\nText:\nDo you have a plan in case of a pool chemical emergency? Learn more here: http://t.co/UePPjwvLcb #watersafety @CDC\n\n____________________ \n\ntarget: 0 (not real diaster)\nText:\nI crashed my car into a parked car the other day... #modestmouseremix #truestory\n\n____________________ \n\ntarget: 0 (not real diaster)\nText:\nsmokers that ruin that new car smell ????\n\n____________________ \n\ntarget: 1 (real diaster)\nText:\n#computers #gadgets Two giant cranes holding a bridge collapse into nearby homes http://t.co/UZIWgZRynY #slingnews\n\n____________________ \n\ntarget: 0 (not real diaster)\nText:\nI love the sound of thunder rumbling across the mountains.\n\n____________________ \n\n","output_type":"stream"}],"execution_count":115},{"cell_type":"markdown","source":"### Split data into training and validation datasets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.014899Z","iopub.execute_input":"2025-10-28T06:45:45.015170Z","iopub.status.idle":"2025-10-28T06:45:45.026386Z","shell.execute_reply.started":"2025-10-28T06:45:45.015143Z","shell.execute_reply":"2025-10-28T06:45:45.025809Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n                                                                            train_df_shuffled[\"target\"].to_numpy(),\n                                                                           test_size=0.1,\n                                                                           random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.027290Z","iopub.execute_input":"2025-10-28T06:45:45.027533Z","iopub.status.idle":"2025-10-28T06:45:45.039253Z","shell.execute_reply.started":"2025-10-28T06:45:45.027514Z","shell.execute_reply":"2025-10-28T06:45:45.038645Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"len(train_sentences),len(train_labels),len(val_sentences),len(val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.039998Z","iopub.execute_input":"2025-10-28T06:45:45.040211Z","iopub.status.idle":"2025-10-28T06:45:45.051500Z","shell.execute_reply.started":"2025-10-28T06:45:45.040188Z","shell.execute_reply":"2025-10-28T06:45:45.050871Z"}},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"(6851, 6851, 762, 762)"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"# check the first ten samples\ntrain_sentences[:10],train_labels[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.052316Z","iopub.execute_input":"2025-10-28T06:45:45.053058Z","iopub.status.idle":"2025-10-28T06:45:45.065117Z","shell.execute_reply.started":"2025-10-28T06:45:45.053030Z","shell.execute_reply":"2025-10-28T06:45:45.064547Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n        'Imagine getting flattened by Kurt Zouma',\n        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n        'destroy the free fandom honestly',\n        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n       dtype=object),\n array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"},"metadata":{}}],"execution_count":119},{"cell_type":"markdown","source":"## Converting text into number, machine learning don't know text.\nwhen dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\nThere are a few ways to do this, namely:\n* *Tokenization* - direct mapping of token (a token could be a word, a character or in between) to number.\n* *Embedding* - Create a matrix of feature vector for each token ( the size of the feature vector can be defined and this embedding can be learned)","metadata":{}},{"cell_type":"markdown","source":"### Text vecorization(tokenization)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import TextVectorization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.065793Z","iopub.execute_input":"2025-10-28T06:45:45.066042Z","iopub.status.idle":"2025-10-28T06:45:45.077514Z","shell.execute_reply.started":"2025-10-28T06:45:45.066019Z","shell.execute_reply":"2025-10-28T06:45:45.076868Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"text_vectorizer = TextVectorization(max_tokens=None, # how many word in the vocablary (automatically add <OOV>\n                                    standardize=\"lower_and_strip_punctuation\",\n                                    split=\"whitespace\",\n                                    ngrams=None, # create groups of n-words\n                                    output_mode=\"int\", # how to map token to number\n                                    output_sequence_length=None ,# how long do you want your sequence to be\n                                    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.078314Z","iopub.execute_input":"2025-10-28T06:45:45.078571Z","iopub.status.idle":"2025-10-28T06:45:45.096144Z","shell.execute_reply.started":"2025-10-28T06:45:45.078549Z","shell.execute_reply":"2025-10-28T06:45:45.095481Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"# find the average number of tokens(words) in the training tweets\nround(sum([len(i.split()) for i in train_sentences]))/len(train_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.096882Z","iopub.execute_input":"2025-10-28T06:45:45.097491Z","iopub.status.idle":"2025-10-28T06:45:45.108906Z","shell.execute_reply.started":"2025-10-28T06:45:45.097469Z","shell.execute_reply":"2025-10-28T06:45:45.108342Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"14.901036345059115"},"metadata":{}}],"execution_count":122},{"cell_type":"code","source":"# setup  text vectorization variables\nmax_vocab_length =10000 # max number of words to have in our vocablary\nmax_length = 15 # max lenght our sequences will be ( e.g how many words from a tweet does a model see?)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.109564Z","iopub.execute_input":"2025-10-28T06:45:45.109760Z","iopub.status.idle":"2025-10-28T06:45:45.124941Z","shell.execute_reply.started":"2025-10-28T06:45:45.109747Z","shell.execute_reply":"2025-10-28T06:45:45.124251Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n                                    output_mode=\"int\",\n                                    output_sequence_length=max_length\n                                   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.126081Z","iopub.execute_input":"2025-10-28T06:45:45.126321Z","iopub.status.idle":"2025-10-28T06:45:45.142206Z","shell.execute_reply.started":"2025-10-28T06:45:45.126300Z","shell.execute_reply":"2025-10-28T06:45:45.141580Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"# Fit the text vectorizer to the training sentence\ntext_vectorizer.adapt(train_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.142932Z","iopub.execute_input":"2025-10-28T06:45:45.143123Z","iopub.status.idle":"2025-10-28T06:45:45.215198Z","shell.execute_reply.started":"2025-10-28T06:45:45.143110Z","shell.execute_reply":"2025-10-28T06:45:45.214606Z"}},"outputs":[],"execution_count":125},{"cell_type":"code","source":"# Create a sample sentence and tokenize it\nsample_sentence = \"There's a flood in my street!\"\ntext_vectorizer([sample_sentence])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.215756Z","iopub.execute_input":"2025-10-28T06:45:45.215954Z","iopub.status.idle":"2025-10-28T06:45:45.231705Z","shell.execute_reply.started":"2025-10-28T06:45:45.215941Z","shell.execute_reply":"2025-10-28T06:45:45.230932Z"}},"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\narray([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]])>"},"metadata":{}}],"execution_count":126},{"cell_type":"code","source":"# Choose a random sentece from the training dataset and tokenize it\nrandom_sentence = random.choice(train_sentences)\nprint(f\"Original text:\\n {random_sentence} \\n\\nVectorized Version: {text_vectorizer(random_sentence)} \")\ntext_vectorizer(random_sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.232412Z","iopub.execute_input":"2025-10-28T06:45:45.232693Z","iopub.status.idle":"2025-10-28T06:45:45.257945Z","shell.execute_reply.started":"2025-10-28T06:45:45.232669Z","shell.execute_reply":"2025-10-28T06:45:45.257370Z"}},"outputs":[{"name":"stdout","text":"Original text:\n Marquei como visto Dragon Ball Super - 1x1 - The God of Destruction\\'s Dream http://t.co/vJLnsKbG86 #bancodeseries \n\nVectorized Version: [5162 5949 4303 3048  794 1058    1    2  200    6    1 1531    1 6135\n    0] \n","output_type":"stream"},{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(15,), dtype=int64, numpy=\narray([5162, 5949, 4303, 3048,  794, 1058,    1,    2,  200,    6,    1,\n       1531,    1, 6135,    0])>"},"metadata":{}}],"execution_count":127},{"cell_type":"code","source":"# check if token is a sentence have the same int value across different sentences\nsample_sentence_two = \"schools are the best Western in Lit lit litterally.. LiTTErALLy..\"\ntext_vectorizer(sample_sentence_two)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T06:45:45.258572Z","iopub.execute_input":"2025-10-28T06:45:45.258750Z","iopub.status.idle":"2025-10-28T06:45:45.274090Z","shell.execute_reply.started":"2025-10-28T06:45:45.258736Z","shell.execute_reply":"2025-10-28T06:45:45.273536Z"}},"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(15,), dtype=int64, numpy=\narray([2718,   22,    2,  149, 1102,    4, 5214, 5214,    1,    1,    0,\n          0,    0,    0,    0])>"},"metadata":{}}],"execution_count":128},{"cell_type":"code","source":"# Get the unique words in the vocabulary\nwords_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in vocabulary\ntop_5_words = words_in_vocab[:5] # get the most common word\nbottom_5_words = words_in_vocab[-5:] # get the least common word\ntop_5_words,bottom_5_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:02:27.050662Z","iopub.execute_input":"2025-10-28T07:02:27.050918Z","iopub.status.idle":"2025-10-28T07:02:27.075508Z","shell.execute_reply.started":"2025-10-28T07:02:27.050902Z","shell.execute_reply":"2025-10-28T07:02:27.074987Z"}},"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"(['', '[UNK]', 'the', 'a', 'in'],\n ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"},"metadata":{}}],"execution_count":134},{"cell_type":"markdown","source":"### Creating and Embedding using an Embedding Layer\nTo make our embedding, we going to use tensorflow embedding layer\nThe parameters we care most about for our embedding layer:\n* `input_dim` = the size of our vocabulary\n* `output_dim` = the size of the output embedding vector,for example, a value of 100 would mean each token gets represented by a vector 100 long\n*  `input_length` = length of the sequences being passed to the embedding layer","metadata":{}},{"cell_type":"code","source":" from tensorflow.keras import layers\nembedding = layers.Embedding(input_dim=max_vocab_length,\n                            output_dim=128,\n                             input_length=max_length\n                            )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:02:32.192979Z","iopub.execute_input":"2025-10-28T07:02:32.193250Z","iopub.status.idle":"2025-10-28T07:02:32.197879Z","shell.execute_reply.started":"2025-10-28T07:02:32.193230Z","shell.execute_reply":"2025-10-28T07:02:32.196998Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"# Get a random sentence from the training set\nrandom_sentence = random.choice(train_sentences)\nprint(f\"original text: \\n{random_sentence} \")\nembedding(text_vectorizer(random_sentence))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:03:30.537883Z","iopub.execute_input":"2025-10-28T07:03:30.538511Z","iopub.status.idle":"2025-10-28T07:03:31.296110Z","shell.execute_reply.started":"2025-10-28T07:03:30.538490Z","shell.execute_reply":"2025-10-28T07:03:31.295503Z"}},"outputs":[{"name":"stdout","text":"original text: \nWest Valley I405 N / Us101 S I405 N Con **Trfc Collision-Unkn Inj** http://t.co/jS9EhP88wQ \n","output_type":"stream"},{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(15, 128), dtype=float32, numpy=\narray([[ 0.02061493, -0.03656311, -0.03316872, ..., -0.02221966,\n        -0.02162361, -0.00464284],\n       [ 0.00368695, -0.00452604,  0.02865795, ..., -0.02712001,\n        -0.04996324,  0.03604457],\n       [-0.02429228, -0.04296454, -0.0297516 , ...,  0.00787184,\n        -0.03596387, -0.00522044],\n       ...,\n       [ 0.03072361,  0.03043249, -0.0384144 , ...,  0.03784957,\n        -0.00117218,  0.000528  ],\n       [-0.02083943, -0.00920706,  0.00987709, ..., -0.01049381,\n         0.01139957,  0.00122079],\n       [-0.02083943, -0.00920706,  0.00987709, ..., -0.01049381,\n         0.01139957,  0.00122079]], dtype=float32)>"},"metadata":{}}],"execution_count":138},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}